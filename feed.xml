<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://seanelvidge.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://seanelvidge.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2026-02-03T04:51:46+00:00</updated><id>https://seanelvidge.github.io/feed.xml</id><title type="html">Sean Elvidge</title><entry><title type="html">When Good Ideas Don’t Survive Contact With Data - A December Football Myth Tested</title><link href="https://seanelvidge.github.io/articles/2025/A_December_Football_Myth/" rel="alternate" type="text/html" title="When Good Ideas Don’t Survive Contact With Data - A December Football Myth Tested"/><published>2025-12-31T19:30:00+00:00</published><updated>2025-12-31T19:30:00+00:00</updated><id>https://seanelvidge.github.io/articles/2025/A_December_Football_Myth</id><content type="html" xml:base="https://seanelvidge.github.io/articles/2025/A_December_Football_Myth/"><![CDATA[<p>Every so often I come up with what feels like a great idea for a blog post. A clever angle, an interesting hypothesis, something that surely must be hiding in the data just waiting to be revealed. And then, after hours of analysis, the result is… nothing. Completely flat. No effect.</p> <p>This is one of those stories.</p> <p>I wanted to look at whether the famously congested English football December schedule gives an advantage to teams (either weaker or stronger teams). With matches every few days, tired legs, rotation, winter weather, and general chaos, it seemed plausible that perhaps squad rotation from the stronger sides might be key, or perhaps stronger sides might stumble more than usual and that underdogs might pick up a few unexpected points.</p> <p>It’s a nice idea. Unfortunately, as we’ll see, a nice idea does not guarantee a nice result.</p> <h2 id="why-december-might-matter">Why December Might Matter</h2> <p>Consider what happens in December in English football:</p> <ul> <li>Fixture congestion increases dramatically.</li> <li>Elite teams face multiple competitions and may rotate heavily.</li> <li>Injuries accumulate and squad depth becomes critical.</li> <li>Weather worsens, pitches soften, and match conditions become less predictable.</li> </ul> <p>Perhaps if stronger teams depend more on structure and precision, and weaker teams rely more on disruption and variance, you can build a reasonable argument that December’s chaos environment might narrow the gap.</p> <p>In other words, if \(S\) is team strength and \(\epsilon\) is “football randomness”, maybe the effective strength looks more like:</p> \[S_{\text{effective}} = S + \epsilon,\] <p>and perhaps December has a larger \(\epsilon\).</p> <p>If so, underdogs might perform better than expected.</p> <h2 id="how-to-measure-underdog-performance">How to Measure “Underdog Performance”?</h2> <p>To test this we need a <a href="https://seanelvidge.com/articles/2024/All_England_football_league_results/">very large dataset of football results</a> and a way to <a href="https://seanelvidge.com/articles/2025/Football_team_rankings/">quantify which team was stronger <em>before</em> the match</a> was played.</p> <p>In the team strength database a higher values means a stronger team.</p> <p>Thus:</p> <ul> <li>The stronger team is whichever side has the higher rank.</li> <li>The weaker team (the “underdog”) is the side with the lower rank.</li> </ul> <p>And for each match, we compute:</p> <ul> <li>Underdog points</li> <li>Underdog goal difference</li> <li>Whether the match took place in December</li> </ul> <p>Everything you’d need to test whether December helps the weaker (or stronger) team.</p> <h2 id="december-vs-non-december-the-raw-numbers">December vs Non-December: The Raw Numbers</h2> <p>Aggregating across every division, every season, and every match where a clear favourite exists, we get:</p> <ul> <li>Outside December, underdogs earn: <strong>1.178 points per match</strong></li> <li>In December, underdogs earn: <strong>1.181 points per match</strong></li> </ul> <p>The difference, <strong>0.0026 points</strong>, is essentially zero.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/ppm_dec_nonDec-480.webp 480w,/assets/img/ppm_dec_nonDec-800.webp 800w,/assets/img/ppm_dec_nonDec-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/ppm_dec_nonDec.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>The underlying distribution of goal differences tells the same story.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Underdog_Goal_Differences-480.webp 480w,/assets/img/Underdog_Goal_Differences-800.webp 800w,/assets/img/Underdog_Goal_Differences-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/Underdog_Goal_Differences.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>I will admit, this was mildly disappointing. But maybe aggregate data hides the truth? Perhaps the Premier League behaves differently? Or lower leagues, with smaller squads, show something?</p> <p>Nope.</p> <p>However you slice the dataset, Tier 1, Tier 2, Tier 3, Tier 4, the same conclusion emerges:</p> <ul> <li>The difference between underdog performance in December vs other months is tiny.</li> <li>In every tier, the effect is statistically insignificant.</li> <li>Some tiers lean slightly positive, others slightly negative, all within noise.</li> </ul> <p>So weaker teams, as a group, do <strong>not</strong> seem to benefit from the December schedule.</p> <p>You might reasonably ask whether the <strong>favourites</strong> show any seasonal change. If weaker teams don’t improve, perhaps stronger teams deteriorate?</p> <p>I ran the same comparison for the stronger side in each match.</p> <p>The result? Exactly the same story.</p> <p>Stronger teams’ points and goal differences in December are statistically indistinguishable from the rest of the season. No noticeable dip, no seasonal weakness, no hidden December curse.</p> <p>In short:</p> <blockquote> <p>Neither underdogs nor favourites show any meaningful change in performance during December.</p> </blockquote> <h2 id="a-more-formal-statistical-model">A More Formal Statistical Model</h2> <p>To be thorough, I fitted a regression model of underdog points:</p> \[\text{pts} = \beta_0 + \beta_1\,\text{December} + \beta_2\,\text{Home} + C(\text{Tier}) + C(\text{Season}) + \varepsilon .\] <p>This controls for:</p> <ul> <li>Home advantage</li> <li>League tier</li> <li>Season-by-season variation</li> </ul> <p>The coefficient for the December effect came out as:</p> \[\beta_1 = -0.0018 \pm 0.013,\] <p>which is, again, indistinguishable from zero.</p> <h2 id="when-a-good-hypothesis-fails">When a Good Hypothesis Fails</h2> <p>This leads to what I think is the most important lesson from the whole exercise.</p> <p>In science many ideas do not survive contact with real data. They’re plausible, they’re elegant, and they would make for a great story, but the universe simply refuses to cooperate.</p> <p>That does not make the work wasted.</p> <p>It makes it honest.</p> <h2 id="the-academic-problem-with-negative-results">The Academic Problem With Negative Results</h2> <p>In academia, “negative” or null results are notoriously hard to publish. Journals often prefer dramatic or surprising findings, which unintentionally encourages selective reporting:</p> <ul> <li>Effects that <strong>don’t</strong> exist are quietly forgotten.</li> <li>Effects that <strong>appear by chance</strong> get published.</li> <li>The literature accumulates exciting stories but not necessarily accurate ones.</li> </ul> <p>This December analysis is a textbook example: an interesting idea, diligently tested, clearly unsupported.</p> <p>Yet these non-effects matter. They give us a clearer picture of reality, and they remind us that the absence of a pattern is itself information, and sometimes, important information.</p>]]></content><author><name></name></author><category term="football"/><category term="mathematics"/><summary type="html"><![CDATA[Every so often I come up with what feels like a good idea for a blog post. But they don't always work out, this is the story of my investigations into the congested English football December schedule and whether it gives certain teams an advantage.]]></summary></entry><entry><title type="html">Christmas Day Football - The Lost Tradition</title><link href="https://seanelvidge.github.io/articles/2025/Christmas_Day_Football/" rel="alternate" type="text/html" title="Christmas Day Football - The Lost Tradition"/><published>2025-12-25T09:00:00+00:00</published><updated>2025-12-25T09:00:00+00:00</updated><id>https://seanelvidge.github.io/articles/2025/Christmas_Day_Football</id><content type="html" xml:base="https://seanelvidge.github.io/articles/2025/Christmas_Day_Football/"><![CDATA[<p>It’s been exactly 60 years since the last English league match was played on Christmas Day. On 25 December 1965, Blackpool hosted Blackburn Rovers in a festive Lancashire derby that would become the final flicker of a long-standing tradition. While Boxing Day remains a staple of the football calendar, the idea of heading to the ground after unwrapping presents has quietly faded into the past. Here’s a look back at how Christmas Day football began, what made it special, and why it came to an end.</p> <h2 id="victorian-beginnings">Victorian Beginnings</h2> <p>The Football League didn’t include Christmas Day matches in its inaugural season (1888), but by the very next year, Preston North End hosted Aston Villa on 25 December 1889. That 3-2 win for Preston drew around 9,000 fans and marked the beginning of Christmas football as a regular fixture.</p> <p>By the early 20th century, the tradition was well-established. Local derbies were often scheduled to reduce travel, and many clubs played the same opponent home and away over Christmas and Boxing Day. It wasn’t unusual for fans to watch a game in the morning and be home in time for turkey in the afternoon.</p> <h2 id="when-christmas-meant-football">When Christmas Meant Football</h2> <p>For much of the 20th century, football on Christmas Day was as normal as carols and crackers. The interwar years and post-WWII period were the high points, with full fixture lists and packed crowds. In 1949, over 3 million fans attended league matches during the Christmas week. Players would sometimes play three matches in four days. Fans shared flasks and sang carols on the terraces.</p> <p>Holiday scheduling quirks added to the charm. Tranmere once lost 4–1 on Christmas Day, only to win the return fixture 13–4 the next day. Matches were sometimes played in snow, fog, or biting cold, but still the crowds came.</p> <p>Christmas Day 1914 was particularly notable. Despite the shadow of World War I, nine First Division matches went ahead, drawing a combined crowd of around 173,000. Football was still seen as a morale-booster, and a newspaper at the time declared that to millions:</p> <blockquote> <p>Christmas without football would not be Christmas at all. (<a href="https://www.britishnewspaperarchive.co.uk/viewer/bl/0000530/19451221/019/0003">Essex Newsman, 21 December, 1945</a>)</p> </blockquote> <p>And across the Channel that same day, one of football’s most poignant and enduring moments occurred. British and German troops along the Western Front took part in the famous 1914 Christmas Truce. In the frozen fields of Flanders, soldiers from both sides briefly set down their arms and came together to sing carols, exchange gifts, and even play informal matches in No Man’s Land.</p> <h2 id="christmas-day-classics">Christmas Day Classics</h2> <p>There were high-scoring thrillers (Chelsea 7–4 Portsmouth in 1957), and even a match in 1940 where Norwich beat a scratch Brighton team 18–0. The largest Christmas Day crowds topped 60,000 at places like Newcastle and Arsenal.</p> <p>Some stories veer into folklore: players turning up tipsy after too much Christmas cheer, supporters pelting the pitch with orange peel, and squads sharing a turkey dinner on the train between back-to-back games.</p> <p>And for Coventry fans: our own Ken Satchwell scored the last ever Football League hat-trick on Christmas Day, in a 5–3 win over Wrexham in 1959. One of the last festive hurrahs before the tradition faded.</p> <h2 id="the-final-whistle-25-december-1965">The Final Whistle: 25 December 1965</h2> <p>60 years ago today, in 1965, Blackpool beat Blackburn Rovers 4–2 in front of just over 20,000 fans. Young Alan Ball, not yet a World Cup winner, scored one of the goals. The weather was chilly but the game was lively, and the matchday programme was wrapped in festive green and tangerine.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Blackpool-Xmas-Day-programme-480.webp 480w,/assets/img/Blackpool-Xmas-Day-programme-800.webp 800w,/assets/img/Blackpool-Xmas-Day-programme-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/Blackpool-Xmas-Day-programme.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>That game became, quietly, the last of its kind.</p> <h2 id="why-it-ended">Why It Ended</h2> <p>The reasons are a mix of culture, logistics, and changing times. More families preferred to stay home on Christmas morning. Public transport no longer ran on Christmas Day. Policing and stewarding became harder to organise. Players were increasingly reluctant to spend Christmas away from their families.</p> <p>The spread of floodlights and TV also meant fixtures could be moved to evenings or rescheduled around the holidays. Boxing Day, a public holiday since the 19th century, proved more popular for fans and clubs alike. By the early 60s, most clubs had already opted out. No ban was needed. The tradition just slipped away.</p> <h2 id="remembering-christmas-football">Remembering Christmas Football</h2> <p>Christmas Day football was sometimes chaotic, often charming, and always memorable. It belongs to another era, one of packed terraces, handwritten programmes, and roaring fires waiting at home. Brentford tried to make it come back in 1983 when the tried to schedule a game for Christmas morning. But fans rebelled and the club backed down.</p> <p>These days, players can enjoy their mince pies in peace, and fans save their voices for Boxing Day.</p> <p>But 60 years ago today, Blackpool beat Blackburn in the last of 1,243 Christmas Day fixtures, as English football took its final bow on December 25th.</p>]]></content><author><name></name></author><category term="football"/><summary type="html"><![CDATA[It's been exactly 60 years since the last English league match was played on Christmas Day. Here’s a look back at how Christmas Day football began, what made it special, and why it came to an end.]]></summary></entry><entry><title type="html">How to Calculate League Position Probabilities</title><link href="https://seanelvidge.github.io/articles/2025/League_table_prediction_probabilities/" rel="alternate" type="text/html" title="How to Calculate League Position Probabilities"/><published>2025-12-22T19:30:00+00:00</published><updated>2025-12-22T19:30:00+00:00</updated><id>https://seanelvidge.github.io/articles/2025/League_table_prediction_probabilities</id><content type="html" xml:base="https://seanelvidge.github.io/articles/2025/League_table_prediction_probabilities/"><![CDATA[<p>By mid-season, football fans instinctively start doing probability in their heads.</p> <blockquote> <p>If we win our next two, and they drop points away at… actually, hang on.</p> </blockquote> <p>This usually ends with a napkin full of scribbles and a strong emotional commitment to a particular set of results. What follows in this post an attempt to do the same thing — but with statistics.</p> <p>On the <a href="https://seanelvidge.com/tableProbs">predicted league tables</a> page of this site you’ll find the probabilities for every team finishing in every possible league position. Not via vast simulations. Not using “expected points” (xPts). Not vibes. Actual probabilities.</p> <p>This post explains how those tables are built, what assumptions sit underneath them, and, importantly, what they don’t claim to do.</p> <h2 id="estimating-the-future">Estimating the future</h2> <p>For each remaining fixture, we estimate the probability of:</p> <ul> <li>a home win,</li> <li>a draw,</li> <li>an away win.</li> </ul> <p>These probabilities come from my <a href="https://seanelvidge.com/articles/2025/Football_team_rankings/">rating model</a> that combines:</p> <ul> <li>team strength,</li> <li>home advantage,</li> <li>historical era-dependent draw rates,</li> </ul> <p>(you can try the <a href="https://seanelvidge.com/matchProbs">match probability calculator</a> yourself).</p> <p>For these forecasts we assume that team strength remains constant for the rest of the season. This is not because teams don’t change, obviously they do, but because this assumption lets us ask a very precise question:</p> <p>“Given what we know right now, what does the future look like?”</p> <p>No form, no momentum, no injuries, no managerial bounce. Just the present frozen in amber.</p> <h2 id="turning-matches-into-points">Turning matches into points</h2> <p>Once we know the probability that a team finishes on, say, 64 points, we can ask the next question:</p> <p>“What position will that correspond to?”</p> <p>For each possible final points total:</p> <ul> <li>we calculate the probability that other teams finish above that total,</li> <li>the probability they finish below it,</li> <li>and the probability they finish on exactly the same points.</li> </ul> <p>When teams are tied on points, we assume a random tie-break between them. This is not how the real leagues work, goal difference matters, but it is a deliberately neutral assumption that avoids injecting additional modelling choices.</p> <p>By aggregating over all possible point totals, we obtain the probability that a given team finishes in position 1, 2, 3, …, N.</p> <p>That’s what fills the table.</p> <p>For example:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/position-odds-2025-2026-EFL_Championship-480.webp 480w,/assets/img/position-odds-2025-2026-EFL_Championship-800.webp 800w,/assets/img/position-odds-2025-2026-EFL_Championship-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/position-odds-2025-2026-EFL_Championship.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <h2 id="why-this-isnt-a-simulation">Why this isn’t a simulation</h2> <p>Many league predictors simulate the rest of the season thousands or millions of times (e.g. <a href="https://theanalyst.com/articles/opta-football-predictions">Opta</a>). Those approaches can be flexible and intuitive. However this approach is different.</p> <p>Here every probability is computed exactly so the results are fully reproducible and even small probabilities (like a 0.3% chance of winning the league) are real, not artefacts of random noise. However the cost of this precision is a stronger set of assumptions, here we assume:</p> <ul> <li>match outcomes are independent,</li> <li>team strengths do not change,</li> <li>tie-breaks are random.</li> </ul> <h2 id="reading-the-table">Reading the table</h2> <p>Each row shows a team; each column shows a finishing position.</p> <ul> <li>A cell marked “12%” means exactly that: a 12% chance of finishing in that position.</li> <li>“&lt;1%” means possible, but very unlikely.</li> <li>“–” means impossible — the team cannot mathematically finish there.</li> </ul> <p>The strongest probability in each row is highlighted, and other positions are shaded relative to it. This gives a quick visual sense of where a team’s likely finishing range lies.</p> <p>This can be hard to see on a mobile scream, so the full table is replaced by a compact summary:</p> <ul> <li>chance of finishing 1st,</li> <li>chance of finishing Top 6,</li> <li>chance of finishing in the Bottom 3.</li> </ul> <p>The full table is always available via a toggle, and the entire table can be downloaded as an image for closer inspection.</p> <h2 id="what-this-doesnt-say">What this doesn’t say</h2> <p>These tables do not say:</p> <ul> <li>who will win the league,</li> <li>that form and injuries don’t matter.</li> </ul> <p>They say something subtler, and, I think, more interesting:</p> <p>“If the football world stays roughly as it is today, how wide is the space of possible futures?”</p> <p>Sometimes that space is narrow. Sometimes it can be surprisingly large.</p> <p>Check out the <a href="https://seanelvidge.com/tableProbs">predicted league tables</a> for yourself. Updated everytime the <a href="https://seanelvidge.com/articles/2024/All_England_football_league_results/">football database</a> is updated.</p>]]></content><author><name></name></author><category term="football"/><category term="mathematics"/><summary type="html"><![CDATA[The methodology behind how I calculate the probabilities of where the different teams in the English football league will end up.]]></summary></entry><entry><title type="html">Tracking Football Team Strengths with a Bayesian Kalman Model</title><link href="https://seanelvidge.github.io/articles/2025/Football_team_rankings/" rel="alternate" type="text/html" title="Tracking Football Team Strengths with a Bayesian Kalman Model"/><published>2025-12-15T09:20:00+00:00</published><updated>2025-12-15T09:20:00+00:00</updated><id>https://seanelvidge.github.io/articles/2025/Football_team_rankings</id><content type="html" xml:base="https://seanelvidge.github.io/articles/2025/Football_team_rankings/"><![CDATA[<p>Not all football-rating systems are the same. Many of the public ones, like the excellent <a href="http://clubelo.com/System">ClubElo</a>, do a fine job of ranking teams using elegant updates. Win and your rating rises, lose and it falls; the amount you move depends on how “surprised” the model was.</p> <p>This model begins in the same spirit but replaces those heuristic updates with a probabilistic engine: a <em>Bayesian Extended Kalman Filter</em> coupled to a modern version of the Bradley–Terry model (with added draws). The core idea is simple: treat each team’s strength as something hidden that we estimate and track through time, with uncertainty that expands between matches and contracts when new results arrive.</p> <p>Across the <a href="https://seanelvidge.com/articles/2024/All_England_football_league_results/">full historical dataset</a> (every English league match since 1888) the system achieves a mean Brier score of 0.2035. These values are significantly better than many published computer models (e.g. <a href="https://www.stat.cmu.edu/cmsac/sure/2023/showcase/soccer/report.html">Nyamdorj et al. 2014</a>, <a href="https://bsic.it/odds-at-play-testing-efficiency-in-the-premier-league-and-serie-a/">BSIC, 2024</a> and <a href="https://harvardsportsanalysis.org/2015/07/5988/">Harvard Sports Analysis Collective, 2015</a>) which indicates a stable, well-calibrated predictive performance. Crucially, because the filter quantifies its own uncertainty, it can tell us not only who is strongest, but how confident we should be in that judgement.</p> <p>The rest of this post goes into the mathematical details of the ranking algorithm, but if you want to access the underlying data it is <a href="https://github.com/seanelvidge/England-football-results">available here</a> (specifically the file <a href="https://raw.githubusercontent.com/seanelvidge/England-football-results/refs/heads/main/EnglandLeagueResults_wRanks.csv"><code class="language-plaintext highlighter-rouge">EnglandLeagueResults_wRanks.csv</code></a>).</p> <h2 id="the-big-picture">The Big Picture</h2> <p>Imagine every team has a hidden “true strength” \(s_i\). Before a match, the home and away teams carry beliefs about their current strengths, each with an associated uncertainty. When they play, the result provides new information that updates those beliefs.</p> <p>In the ClubElo framework this update is written directly as</p> \[R_{\text{new}} = R_{\text{old}} + K(S - E),\] <p>where \(S\) is the score (1 for a win, 0.5 for a draw, 0 for a loss), \(E\) is the expected probability, and \(K\) is a fixed responsiveness parameter.</p> <p>Here, the same logic is embedded in a <a href="https://en.wikipedia.org/wiki/Kalman_filter">Kalman filter</a>, which means the effective \(K\) is learned automatically. The update size depends on two things: how uncertain we are about the teams, and how surprising the result was. Upsets between uncertain teams lead to large updates; shocks between well-understood teams barely move the needle.</p> <p>Between matches, team strengths are not frozen. Instead, they evolve according to a <em>mean-reverting stochastic process</em>, allowing form to drift while preventing runaway behaviour. Newly promoted teams begin with large uncertainty and adapt quickly; established teams gravitate toward long-term baselines rather than rising indefinitely.</p> <h2 id="modelling-match-outcomes-wins-draws-losses">Modelling Match Outcomes (Wins, Draws, Losses)</h2> <p>Match outcomes are modelled using the <a href="https://www.jstor.org/stable/2283595">Davidson extension</a> of the <a href="https://en.wikipedia.org/wiki/Bradley%E2%80%93Terry_model">Bradley–Terry model</a>, which naturally incorporates draws. The probability of each outcome is</p> \[\Pr(\text{Home}) = \frac{e^{\Delta}}{e^{\Delta} + e^{-\Delta} + \kappa},\] \[\Pr(\text{Draw}) = \frac{\kappa}{e^{\Delta} + e^{-\Delta} + \kappa},\] \[\Pr(\text{Away}) = \frac{e^{-\Delta}}{e^{\Delta} + e^{-\Delta} + \kappa},\] <p>where</p> \[\Delta = \beta \bigl(s_H - s_A + h\bigr).\] <p>Here, \(s_H\) and \(s_A\) are the latent strengths of the home and away teams, \(\beta\) is a scaling parameter, \(\kappa\) controls the draw rate, and \(h\) is the home-advantage term.</p> <h2 id="home-advantage---explicit-and-time-varying">Home Advantage - Explicit and Time-Varying</h2> <p>Home advantage is not treated as a fixed constant. Instead, it is explicitly modelled and allowed to vary over time. Historical analysis shows that home-win rates in English football have declined dramatically since the late 19th century, falling from well above 60% to closer to 40–45% in the modern era (see <a href="https://seanelvidge.com/articles/2025/Home_advantage_in_English_football/">this analysis</a>).</p> <p>By allowing the home-advantage parameter \(h\) to evolve slowly with time, the model correctly distinguishes between a home match in 1890 and one in 2025. This prevents systematic bias when comparing teams across eras and is a key improvement over static-advantage rating systems.</p> <h2 id="validation-and-rating-scale">Validation and Rating Scale</h2> <p>Predictive accuracy is measured using the <a href="https://en.wikipedia.org/wiki/Brier_score">Brier score</a>, defined as the mean squared error between predicted probabilities and observed outcomes. Over the full dataset the score is 0.2035 (for the 2024/25 season it is 0.2085), indicating robust calibration both historically and in the present day.</p> <p>Internally, the filter operates on a latent “skill” scale roughly spanning \(-3\) to \(+3\). However for presentation, these values are mapped linearly onto an Elo-style scale, centred on 1000 points, with elite teams reaching 1800+ and lower-league teams clustering about a thousand points below. This transformation is purely cosmetic; all inference happens on the latent scale.</p> <h1 id="part-ii--if-you-dare-read-on-the-mathematics">Part II — If You Dare Read On: The Mathematics</h1> <h2 id="1-state-evolution-ornsteinuhlenbeck-dynamics">1. State Evolution (<a href="https://en.wikipedia.org/wiki/Ornstein%E2%80%93Uhlenbeck_process">Ornstein–Uhlenbeck</a> Dynamics)</h2> <p>Each team’s latent strength evolves as</p> \[s_{i,t+1} = \rho\, s_{i,t} + (1 - \rho)\, \mu_{\text{tier}(i,t)} + \varepsilon_{i,t},\] <p>with</p> \[\varepsilon_{i,t} \sim \mathcal{N}(0, q_i).\] <p>Here, \(\rho\) controls persistence, \(\mu_{\text{tier}}\) is the long-term baseline for the team’s division tier, and \(q_i\) is the process variance. This formulation allows ratings to drift while remaining anchored to realistic league-level expectations.</p> <h2 id="2-observation-model">2. Observation Model</h2> <p>Given predicted strengths \(s_H\) and \(s_A\), the model produces a probability vector</p> \[\mathbf{p} = \begin{bmatrix} p_H \\ p_D \\ p_A \end{bmatrix},\] <p>using the Davidson–Bradley–Terry equations above. The Jacobian matrix \(H\) is computed by differentiating \(\mathbf{p}\) with respect to the state vector \([s_H, s_A]^T\), enabling linearisation of the nonlinear observation model.</p> <h2 id="3-extended-kalman-filter-update">3. Extended Kalman Filter Update</h2> <p>Prediction step:</p> \[x^- = F x_t,\] \[P^- = F P_t F^\top + Q,\] <p>where \(F = \rho I\) and \(Q\) is the process-noise covariance.</p> <p>Observation noise:</p> \[R = \operatorname{diag}(\mathbf{p}) - \mathbf{p}\mathbf{p}^\top.\] <p>Update step:</p> \[K = P^- H^\top \bigl(H P^- H^\top + R\bigr)^{-1},\] \[x_{t+1} = x^- + K (y - \mathbf{p}),\] \[P_{t+1} = (I - K H) P^-.\] <p>The Kalman gain \(K\) replaces the fixed \(K\)-factor of traditional Elo systems, adapting automatically to uncertainty and surprise. A secondary control loop monitors the normalised innovation squared to ensure statistical consistency over time.</p> <h2 id="why-this-matters">Why This Matters</h2> <p>This framework enforces mathematical honesty. Uncertainty is explicit, calibration is measurable, and every parameter (\(\beta\), \(\rho\), \(q\), \(\kappa\), tier baselines, and historical home advantage) has a clear interpretation. Instead of a single magic constant, the model becomes a living system that adapts across seasons, divisions, and eras.</p>]]></content><author><name></name></author><category term="football"/><category term="mathematics"/><summary type="html"><![CDATA[The methodology behind my football team strength model.]]></summary></entry><entry><title type="html">Football Bogey Grounds and How Statistics Can Prove Them</title><link href="https://seanelvidge.github.io/articles/2025/Football_bogey_grounds/" rel="alternate" type="text/html" title="Football Bogey Grounds and How Statistics Can Prove Them"/><published>2025-12-12T19:04:00+00:00</published><updated>2025-12-12T19:04:00+00:00</updated><id>https://seanelvidge.github.io/articles/2025/Football_bogey_grounds</id><content type="html" xml:base="https://seanelvidge.github.io/articles/2025/Football_bogey_grounds/"><![CDATA[<p>Football supporters are never short of folklore. Some of it heroic, some of it tragic, and some of it mathematically suspicious. Among the more enduring tales is the <em>bogey ground</em>: that one venue where your club never quite manages to win, no matter how many times the fixture computer sends you there with fresh optimism, a new manager and a good run of form.</p> <p>But one question always pops up in the back of my mind when I hear this: When is a bogey ground actually a bogey ground, and when is it just a trick of small numbers?</p> <p>Most fans instinctively understand the point. Losing your only ever visit to Carlisle does not make Brunton Park a cursed ground. A couple of failed trips to Luton are not evidence of eldritch forces at work. Yet, scattered across the long history of English league football, a few pairs of teams have met often enough, and still produced zero away wins, that bogey grounds become statistically real.</p> <p>In the Premier League an example of this is Fulham, and their trips to Arsenal.</p> <p>Fulham have played 32 league matches away at Arsenal. They have never won.</p> <p>Not once. Not in 1914 (lost 2-0). Not in 1964 (2-2). Not in 2014 (lost 2-0).</p> <p>Zero wins from thirty-two attempts. Seven draws. Twenty-five defeats.</p> <p>Even more striking, this isn’t just a bad example, this is, among every club in the entire Football League dataset, over 135 years of football, no team has a larger, more emphatic, more mathematically convincing record of away futility than Fulham at Arsenal.</p> <p>So let’s take a look, not just at the record itself, but at how we can quantify bogeyness in a way that recognises your intuition (“two games aren’t enough!”) but takes advantage of the huge dataset football provides.</p> <h2 id="why-never-won-isnt-enough-the-curse-of-small-n">Why “never won” isn’t enough (the curse of small \(n\))</h2> <p>Imagine you flip a coin twice and get two tails. Does that mean the coin is biased?</p> <p>Of course not. You need <em>more</em> flips before you start thinking that someone is up.</p> <p>The same goes for football. A team losing its only away visit to Manchester City tells you nothing. Losing twice? Still nothing except a faint sense of déjà vu. Losing five times? Now you’re paying attention. Losing ten times? Stop buying tickets to the away game.</p> <p>So what we need is a way of answering this question:</p> <p>Given a team has played \(n\) away matches at a ground and won none, what is a reasonable upper limit on how good their <em>true</em> chance of winning there might be?</p> <p>Fortunately statistics, as it always does, gives us a handy tool for working this out, the <a href="https://en.wikipedia.org/wiki/Binomial_proportion_confidence_interval#Wilson_score_interval">Wilson confidence interval.</a></p> <h2 id="a-gentle-introduction-to-the-wilson-interval">A (gentle) introduction to the Wilson interval</h2> <p>Don’t panic; no equations are necessary. Just an idea. A Wilson interval takes two bits of information:</p> <ul> <li>the number of games played (\(n\)), and</li> <li>the number of games won (0, in our bogey-ground case)</li> </ul> <p>and asks:</p> <p>“If their true underlying chance of winning were \(p\), how big could \(p\) realistically be before the observed data (zero wins) would start to look implausible?”</p> <p>For small \(n\) (not many games played) the answer is: “\(p\) could still be quite large.”</p> <p>For large \(n\) (a large number of games played) the answer is: “\(p\) must be quite small.”</p> <p>This lines up with our intuition.</p> <p>A team with 0 wins from 2 tries? Their true win rate might easily be 30%, 40%, even 50%.</p> <p>A team with 0 wins from 32 tries? Now the interval collapses. It tells you the true away win probability is almost certainly very small, low enough that even by bad luck alone, you’d be surprised <em>not</em> to have picked up a single win after that many attempts.</p> <p>The Wilson interval is good for this particular problem (compared to other approaches like the Wald Interval) because it behaves properly at the boundaries (like at 0% or 100%), where ordinary methods can breakdown. Football fans should love it because it gives scientific legitimacy to something they’ve always known: <strong>some bogey grounds are imaginary, but a few are real</strong>.</p> <h2 id="the-most-convincing-bogey-of-them-all-fulham-at-arsenal">The most convincing bogey of them all: Fulham at Arsenal</h2> <p>So, what does Wilson say about Fulham’s 0 wins from 32 away league games at Arsenal?</p> <p>It says this:</p> <blockquote> <p>In each of Fulham’s away matches against Arsenal their probability of winning must have been (at the very most) 10% for 0 wins out of 32 to not be statistically suspicious.</p> </blockquote> <p>Mathematically this comes from plugging \(n\) (number of games) and \(z\) (which is equal to 1.96 for 95% ‘confidence’) into the equation for calculating the upper bound of the Wilson interval:</p> \[\mbox{Wilson Upper Bound} = \frac{z^2}{n+z^2} = \frac{1.96^2}{32+1.96^2} = 0.107 = 10.7\%\] <p>So the only way we could avoid saying Arsenal is Fulham’s away team nemesis is if we believe Fulham, across the whole history of the fixture (starting in 1913; <a href="https://seanelvidge.com/h2h?team1=Arsenal&amp;team2=Fulham">see my head-to-head tool here</a>), have not had better than a 10% chance of winning those games. Whilst we can’t be (mathematically) certain that it is true, it is incredibly unlikely. Typical away win rates in the top division over history are roughly 25-30% range. Even clear cut underdogs often have pre-match win probabilities around 15-20%.</p> <p>So, therefore, I think it is safe to say to conclude:</p> <blockquote> <p>Fulham away at Arsenal is not just a bogey ground, it is the bogey ground.</p> </blockquote> <p>The Premier League’s most mathematically defensible curse.</p> <h2 id="other-bogey-teams">Other bogey teams</h2> <p>Fulham–Arsenal is the only pair in the <a href="https://seanelvidge.com/articles/2024/All_England_football_league_results/">entire database</a> whose Wilson upper bound hovers at just above the 10% threshold. But several others get close, here are the best (or worst) of the rest:</p> <table style="border-collapse: collapse; width: 75%;"> <thead> <tr> <th style="border: 1px solid black; padding: 8px;">Away Team</th> <th style="border: 1px solid black; padding: 8px;">Home Team</th> <th style="border: 1px solid black; padding: 8px;">Played</th> <th style="border: 1px solid black; padding: 8px;">Record</th> <th style="border: 1px solid black; padding: 8px;">Wilson Upper</th> </tr> </thead> <tbody> <tr> <td style="border: 1px solid black; padding: 8px;">Fulham</td> <td style="border: 1px solid black; padding: 8px;">Arsenal</td> <td style="border: 1px solid black; padding: 8px;">32</td> <td style="border: 1px solid black; padding: 8px;">0W–7D–25L</td> <td style="border: 1px solid black; padding: 8px;">10.7%</td> </tr> <tr> <td style="border: 1px solid black; padding: 8px;">Grimsby Town</td> <td style="border: 1px solid black; padding: 8px;">Blackburn Rovers</td> <td style="border: 1px solid black; padding: 8px;">28</td> <td style="border: 1px solid black; padding: 8px;">0W–9D–19L</td> <td style="border: 1px solid black; padding: 8px;">12.1%</td> </tr> <tr> <td style="border: 1px solid black; padding: 8px;">Mansfield Town</td> <td style="border: 1px solid black; padding: 8px;">Reading</td> <td style="border: 1px solid black; padding: 8px;">26</td> <td style="border: 1px solid black; padding: 8px;">0W–5D–21L</td> <td style="border: 1px solid black; padding: 8px;">12.9%</td> </tr> <tr> <td style="border: 1px solid black; padding: 8px;">Tranmere Rovers</td> <td style="border: 1px solid black; padding: 8px;">Barnsley</td> <td style="border: 1px solid black; padding: 8px;">26</td> <td style="border: 1px solid black; padding: 8px;">0W–11D–15L</td> <td style="border: 1px solid black; padding: 8px;">12.9%</td> </tr> <tr> <td style="border: 1px solid black; padding: 8px;">Oldham Athletic</td> <td style="border: 1px solid black; padding: 8px;">Charlton Athletic</td> <td style="border: 1px solid black; padding: 8px;">25</td> <td style="border: 1px solid black; padding: 8px;">0W–11D–14L</td> <td style="border: 1px solid black; padding: 8px;">13.3%</td> </tr> <tr> <td style="border: 1px solid black; padding: 8px;">Newport County</td> <td style="border: 1px solid black; padding: 8px;">Luton Town</td> <td style="border: 1px solid black; padding: 8px;">24</td> <td style="border: 1px solid black; padding: 8px;">0W–7D–17L</td> <td style="border: 1px solid black; padding: 8px;">13.8%</td> </tr> <tr> <td style="border: 1px solid black; padding: 8px;">Coventry City</td> <td style="border: 1px solid black; padding: 8px;">Preston North End</td> <td style="border: 1px solid black; padding: 8px;">24</td> <td style="border: 1px solid black; padding: 8px;">0W–9D–15L</td> <td style="border: 1px solid black; padding: 8px;">13.8%</td> </tr> </tbody> </table> <p><br/></p> <p>These are not small samples. These are not casual coincidences. When you are approaching 20 or 30 visits with no victory, it is time to stop thinking you are unlucky and start accepting you have a bogey ground.</p>]]></content><author><name></name></author><category term="football"/><category term="mathematics"/><summary type="html"><![CDATA[Can a football club actually have a statistically verifiable football bogey ground or is it just bad luck?]]></summary></entry><entry><title type="html">40 points to avoid relegation?</title><link href="https://seanelvidge.github.io/articles/2025/40_points_to_avoid_relegation/" rel="alternate" type="text/html" title="40 points to avoid relegation?"/><published>2025-11-08T23:04:00+00:00</published><updated>2025-11-08T23:04:00+00:00</updated><id>https://seanelvidge.github.io/articles/2025/40_points_to_avoid_relegation</id><content type="html" xml:base="https://seanelvidge.github.io/articles/2025/40_points_to_avoid_relegation/"><![CDATA[<html> <head> <style>.chart-figure{width:100%;margin:1rem 0}.chart-container{position:relative;width:100%;height:55vh;min-height:420px;max-height:80vh}.chart-container canvas{width:100%!important;height:100%!important;display:block}@media(max-width:640px){.chart-container{height:65vh;min-height:480px}}</style> </head> </html> <p>The number has become part of Premier League folk law. Forty points. Reach 40 and you can relax, the trapdoor to the Championship won’t open.</p> <p>At the start of the 2015/16 season (the season Leicester City won the League!) their manager Claudio Ranieri set them the target of reaching 40 points to avoid relegation. When they hit the target:</p> <blockquote> <p>“We have 40 points which was the goal. It’s champagne for my players!”</p> </blockquote> <blockquote> <p>Claudio Ranieri, 2 Jan, 2016.</p> </blockquote> <p>But where did this number come from, and it is the right target?</p> <p>Many people have noted that the 40 point mark is a “myth” (e.g. <a href="https://www.premierleague.com/en/news/3932287">The Premier League</a>, <a href="https://www.bbc.co.uk/sport/football/43049564">BBC</a>, <a href="https://www.nytimes.com/athletic/6126560/2025/02/12/leicester-city-fixtures-premier-league-relegation/">The Athletic</a>). But those articles are really just saying that, on average, you need less than 40 points to survive (and the number of points you need seems to be decreasing).</p> <figure class="chart-figure"> <div class="chart-container"> <canvas id="pointsChart"></canvas> </div> <figcaption></figcaption> </figure> <p>The plot above shows the number of points required to stay in the top division of English football since 3 points for a win was introduced in 1985 (this includes before the Premier League started in 1992). The league tables were created using my <a href="https://seanelvidge.com/leaguetable">arbitrary league table generator</a>. It is also worth noting that during the time range there have been a varying number of teams in the top division (between 20 and 22) which obviously impacts the points required. We have normalized this to a 38-game season for comparison.</p> <p>A few things are immediatly obvious:</p> <ol> <li>Most of the time you do not need 40 points to avoid relegation (34/44; 77%),</li> <li>The average number of points needed to avoid relegation over the last 40 years is 37 (in the Premier League era, it is 36 points),</li> <li>There is a clear decreasing trend of the number of points required.</li> </ol> <p>So where does the idea that you need 40 points come from? There is no obvious origin of the phrase. My best guess is that in the mid 90s, after Southampton survied (just, on goal difference) with 38 points in 1995/96, followed by Coventry City with 41 the following year, then Everton with 40 and then Southampton (again) with 41 points in 1998/99, that that run of four was enough for the (rough) number to stick.</p> <p>But despite the previous analysis (by me and many others) I think 40 is still the correct, pre-season, target. Moving to (for example) a 37 point target would only give you slightly better than a 50-50 chance of staying up (54.5%). Perhaps you would like a little more certainty…</p> <p>One way to look at this is to calculate the cumulative distribution function (CDF). The CDF is a function that shows the probability that a random variable is less than or equal to a specific value. It “accumulates” or “adds up” the probabilities for all outcomes up to a certain point.</p> <figure class="chart-figure"> <div class="chart-container"> <canvas id="cdfChart"></canvas> </div> <figcaption></figcaption> </figure> <p>The above figure shows two, slightly different, CDFs, in blue across the whole dataset (since 1985) and in red just in the Premier League era. To read the plot look at the number of points on the x-axis and then read off the corresponding probability of avoiding relegation on the y-axis for that number of points.</p> <p>Now the 40 point value makes a lot more sense, as it gives a team over an 80% chance of staying in the division, now I prefer those odds!</p> <p>So, whilst there are plenty of posts online telling you that the 40 point target is a myth, I think, as pre-season target for teams, it is still a good one.</p> <script src="https://cdn.jsdelivr.net/npm/chart.js@4"></script> <canvas id="pointsChart"></canvas> <script>function formatSeason(t){const e=parseInt(t,10);return`${e-1}/${String(e).slice(-2).padStart(2,"0")}`}function linearFit(t,e){const a=t.length,r=t.reduce((t,e)=>t+e,0),o=e.reduce((t,e)=>t+e,0),i=(a*t.reduce((t,a,r)=>t+a*e[r],0)-r*o)/(a*t.reduce((t,e)=>t+e*e,0)-r*r);return{m:i,c:(o-i*r)/a}}const chartData={datasets:[{label:"(Normalized) Points Needed to Avoid Relegation",data:[{x:"1982",y:38.9},{x:"1983",y:43.4},{x:"1984",y:44.3},{x:"1985",y:45.2},{x:"1986",y:38},{x:"1987",y:38.9},{x:"1988",y:34.2},{x:"1989",y:40},{x:"1990",y:44},{x:"1991",y:38},{x:"1992",y:38.9},{x:"1993",y:45.2},{x:"1994",y:38.9},{x:"1995",y:39.8},{x:"1996",y:39},{x:"1997",y:41},{x:"1998",y:41},{x:"1999",y:37},{x:"2000",y:34},{x:"2001",y:35},{x:"2002",y:37},{x:"2003",y:43},{x:"2004",y:34},{x:"2005",y:34},{x:"2006",y:35},{x:"2007",y:39},{x:"2008",y:37},{x:"2009",y:35},{x:"2010",y:31},{x:"2011",y:40},{x:"2012",y:37},{x:"2013",y:37},{x:"2014",y:34},{x:"2015",y:36},{x:"2016",y:38},{x:"2017",y:35},{x:"2018",y:34},{x:"2019",y:35},{x:"2020",y:35},{x:"2021",y:29},{x:"2022",y:36},{x:"2023",y:35},{x:"2024",y:27},{x:"2025",y:26}],errorBars:{"(Normalized) Points Needed to Avoid Relegation":[]}}]},years=chartData.datasets[0].data.map(t=>t.x),yPoints=chartData.datasets[0].data.map(t=>t.y),xNums=years.map(t=>parseInt(t,10)),{m:m,c:c}=linearFit(xNums,yPoints),fitY=xNums.map(t=>m*t+c),primaryDataset={label:"(Normalized) Points Needed to Avoid Relegation",data:yPoints,borderColor:"blue",borderWidth:2,pointRadius:2,tension:0},fortyLine={label:"40-point benchmark",data:years.map(()=>40),borderColor:"red",borderWidth:2,pointRadius:0,tension:0,fill:!1,order:0},fitLine={label:"Linear fit",data:fitY,borderColor:"grey",borderWidth:2,borderDash:[6,4],pointRadius:0,tension:0,fill:!1,order:2},vertical1993={label:"Start of Premier League",data:[{x:"1993",y:25},{x:"1993",y:50}],borderColor:"purple",borderWidth:.5,pointRadius:0,tension:0,fill:!1,borderDash:[10,10],order:3},ctx=document.getElementById("pointsChart").getContext("2d");new Chart(ctx,{type:"line",data:{labels:years,datasets:[fortyLine,primaryDataset,fitLine,vertical1993]},options:{responsive:!0,maintainAspectRatio:!1,plugins:{legend:{position:"top"},tooltip:{callbacks:{title:t=>formatSeason(t[0].label)}}},scales:{x:{type:"category",title:{display:!0,text:"Season"},ticks:{callback:function(t){const e=this.getLabelForValue(t);return parseInt(e,10)%5==0?formatSeason(e):""},maxRotation:0,autoSkip:!1}},y:{title:{display:!0,text:"Points"},beginAtZero:!1}},interaction:{mode:"nearest",intersect:!1}}});</script> <script>const cdfPercents=[0,0,0,0,0,0,0,0,0,0,0,2.27,4.55,4.55,6.82,6.82,9.09,9.09,9.09,20.45,38.64,43.18,54.55,61.36,75,81.82,86.36,86.36,88.64,93.18,95.45,100,100,100,100,100,100,100,100,100,100],cdfPremier=[0,0,0,0,0,0,0,0,0,0,0,3.03,6.06,6.06,9.09,9.09,12.12,12.12,12.12,27.27,48.48,54.55,69.7,72.73,81.82,87.88,93.94,93.94,96.97,96.97,96.97,100,100,100,100,100,100,100,100,100,100],cdfData1=cdfPercents.map((t,e)=>({x:e+15,y:t})),cdfData2=cdfPremier.map((t,e)=>({x:e+15,y:t})),cdfCtx=document.getElementById("cdfChart").getContext("2d");new Chart(cdfCtx,{type:"line",data:{datasets:[{label:"Historical CDF",data:cdfData1,stepped:!0,borderWidth:2,pointRadius:0},{label:"Premier League Era CDF",data:cdfData2,stepped:!0,borderWidth:2,borderDash:[6,4],pointRadius:0}]},options:{parsing:!1,maintainAspectRatio:!1,scales:{x:{type:"linear",min:15,max:55,ticks:{stepSize:5},title:{display:!0,text:"Points"}},y:{min:0,max:100,ticks:{callback:t=>t+"%"},title:{display:!0,text:"Cumulative probability (%)"}}},plugins:{legend:{display:!0},tooltip:{callbacks:{label:t=>`P(X \u2264 ${t.parsed.x}) = ${t.parsed.y.toFixed(2)}%`}}},elements:{line:{tension:0}}}});</script>]]></content><author><name></name></author><category term="football"/><category term="mathematics"/><summary type="html"><![CDATA[40 points is the classic benchmark to avoid relegation from the Premier League, is this the right value?]]></summary></entry><entry><title type="html">New space weather modelling suite enables upper atmosphere forecasting</title><link href="https://seanelvidge.github.io/articles/2025/New_space_weather_modelling_suite/" rel="alternate" type="text/html" title="New space weather modelling suite enables upper atmosphere forecasting"/><published>2025-10-08T14:31:00+00:00</published><updated>2025-10-08T14:31:00+00:00</updated><id>https://seanelvidge.github.io/articles/2025/New_space_weather_modelling_suite</id><content type="html" xml:base="https://seanelvidge.github.io/articles/2025/New_space_weather_modelling_suite/"><![CDATA[<p>A pioneering new space weather forecasting modelling suite will enable operational modelling of the upper atmosphere at the Met Office for the first time in a major breakthrough for UK atmospheric science.</p> <p>The Advanced Ensemble Networked Assimilation System (AENeAS) is a new suite of space weather forecasting models available to the Met Office that focuses on how space weather can influence the thermosphere and ionosphere here on Earth.</p> <p>The suite, built at the University of Birmingham, and developed in collaboration with Lancaster University, the Universities of Leeds, Bath and Leicester and the British Antarctic Survey is now running on the Met Office’s new supercomputer.</p> <blockquote> <p>The deployment of this suite at the UK Met Office is the realization of a 10-year vision of SERENE, to build and deliver a state-of-the-art upper atmosphere modelling capability into operational use. The tools will be able to support a wide range of users and ultimately allow people to make informed decisions earlier, being proactive rather than reactive in their response to space weather.</p> </blockquote> <p><strong>Professor Sean Elvidge, Head of Space Environment and Radio Engineering (SERENE) - University of Birmingham</strong></p> <p>Complementing the Met Office’s existing space weather forecasting models, which include predicting the arrival of events from the surface of the Sun, this system introduces new forecasting capability for modelling impacts from space weather on satellites, aviation, communications and services which rely on GNSS.</p> <p>Professor Sean Elvidge, Head of Space Environment and Radio Engineering (SERENE) at the University of Birmingham, and the lead developer of the system said: “The deployment of this suite at the UK Met Office is the realization of a 10-year vision of SERENE, to build and deliver a state-of-the-art upper atmosphere modelling capability into operational use.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/aeneas_day_group-480.webp 480w,/assets/img/aeneas_day_group-800.webp 800w,/assets/img/aeneas_day_group-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/aeneas_day_group.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>“The tools will be able to support a wide range of users and ultimately allow people to make informed decisions earlier, being proactive rather than reactive in their response to space weather.”</p> <p>The new suite means that, for the first time, forecasters at the Met Office Space Weather Operations Centre (MOSWOC) will have access to forecast model output on the impacts of space weather on the ionosphere, as well as enhanced modelling of the thermosphere.</p> <blockquote> <p>Once again, cutting-edge British innovation is making a remarkable difference to our daily lives - this time from way up in the atmosphere. This is a really exciting example of how better understanding of what’s happening in space can protect the tech we all rely on, from GPS on our phones to keeping the power grid working.</p> </blockquote> <p><strong>UK Science Minister Lord Vallance</strong></p> <p>Met Office Space Weather Manager Simon Machin said: “This delivers a world-leading capability that provides greater confidence and forecasting skill than any models currently in operation anywhere else in the world.</p> <p>“This isn’t just about science - it’s about protecting the systems we rely on every day. From aircraft communications to GPS in your phone, space weather can affect us all.”</p> <p>Science Minister Lord Vallance said: “Once again, cutting-edge British innovation is making a remarkable difference to our daily lives - this time from way up in the atmosphere.</p> <p>“This is a really exciting example of how better understanding of what’s happening in space can protect the tech we all rely on, from GPS on our phones to keeping the power grid working.”</p> <p>The new modelling capability will be able to assimilate near real-time data about the current state of the ionosphere and thermosphere, combine with forecasts of solar activity from the Sun to produce accurate and actionable forecasts of the upper atmosphere. This will help enable service providers to take mitigating actions to prevent impacts from space weather where possible.</p> <p>Professor Farideh Honary from Lancaster University said: “We are happy to see our research being translated into a useful product to be used by industry. The research and modelling led by Lancaster is relevant to the aviation industry and in particular to flights using polar routes which are dependent on high frequency communications.</p> <p>“These flights have significantly increased since their initial opening in the 1990s due to their operational advantages such as reduced flight times and fuel consumption, which translate to cost savings and environmental benefits like lower carbon emissions.”</p> <p>More accurate and precise forecast information will help enable service providers to take mitigating actions to prevent impacts from space weather where possible. One example of this is with users of Global Navigation Satellite Systems (GNSS), such as GPS, for positioning or navigational purposes. If they understand that there is likely to be a loss of accuracy in GNSS, they can switch to using other systems.</p> <p>Together, the new modelling suite has been delivered as part of Space Weather Instrumentation, Measurement, Modelling and Risk (SWIMMR) programme, which was funded through the UKRI Strategic Priorities Fund and designed to enhance the UK’s capability for monitoring, modelling and forecasting space weather.</p> <p>Professor Ian McCrea, SWIMMR Programme Lead at STFC RAL Space, said: “These new models represent a significant step forward for the UK’s capacity to model, forecast, and understand key components of our upper atmosphere. By coupling advances in physical modelling with global scale observations, they will enable unparalleled awareness of Earth’s geospatial environment.</p> <p>“The models promise to address a wide range of use cases, ranging from radio communications to the prediction of satellite orbits, and we expect that they will be of great importance to a huge variety of stakeholders. They also provide a clear demonstration of how the collaboration between academics and end users, which SWIMMR has enabled, can benefit members of both communities.”</p>]]></content><author><name></name></author><category term="spaceWeather"/><summary type="html"><![CDATA[New suite of space weather forecasting models focuses on how space weather can influence the thermosphere and ionosphere here on Earth.]]></summary></entry><entry><title type="html">The Trend in Taylor Swift’s Mood</title><link href="https://seanelvidge.github.io/articles/2025/Taylor-Swifts-Mood/" rel="alternate" type="text/html" title="The Trend in Taylor Swift’s Mood"/><published>2025-10-04T12:00:00+00:00</published><updated>2025-10-04T12:00:00+00:00</updated><id>https://seanelvidge.github.io/articles/2025/Taylor-Swifts-Mood</id><content type="html" xml:base="https://seanelvidge.github.io/articles/2025/Taylor-Swifts-Mood/"><![CDATA[<p>Taylor Swift doesn’t just release albums, she releases chapters of her life. From the optimism of <em>Fearless</em> to the bite of <em>Reputation</em>, from the hushed poetry of <em>folklore</em> to the midnight reflections of, well, <em>Midnights</em>. Each album is often thought of as a snapshot of where she was at that moment in time.</p> <p>But can we actually see that story in the music itself? I thought I’d try.</p> <p>The chart below shows an experiment: every dot is a Taylor Swift song, plotted by its “average pitch”. The black line is the overall trend album by album, a kind of data-driven glimpse into her changing musical mood.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/TaylorSwiftMood-480.webp 480w,/assets/img/TaylorSwiftMood-800.webp 800w,/assets/img/TaylorSwiftMood-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/TaylorSwiftMood.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Here’s how it works. Every song can be broken down into thousands of tiny audio frames, and we can estimate the pitch of each. You could then just average all those frames/estimated pitches together, but then you end up something pretty meaningless: a whispered aside would count the same as a belted chorus.</p> <p>Instead, I weighted each frame by its ‘loudness’. Big, bold notes dominate, quiet moments barely move the needle. Mathematically the “weighted average pitch” looks like this:</p> \[M = \frac{\sum_{i=1}^{N}w_im_i}{\sum_{i=1}^{N}w_i},\] <p>where \(m_i\) is the pitch of a frame (in MIDI numbers) and \(w_i\) is how loud it was. Here we do this in “MIDI” because it is a musical scale. Every step is a semitone. If we used raw frequency in Hertz the maths would skew towards the low notes in a way that doesn’t really match how we actually hear music.</p> <p>So, if you look at our plot, focusing on the smoothed black line, a story starts to appear:</p> <ul> <li>Early albums like <em>Fearless</em> are higher up the stave, matching the wide-eyed optimism of youth.</li> <li><em>1989</em> soars with big pop anthems.</li> <li>Then comes the brooding dip of <em>Reputation</em>, the fallout years.</li> <li>During lockdown, <em>folklore</em> and <em>evermore</em> settle into quieter, lower ground.</li> <li><em>Midnights</em> stays low, steeped in melancholy.</li> <li>And then <em>The Tortured Poets Department</em> plunges deepest of all.</li> <li>Then finally with <em>The Life of a Showgirl</em>, the line bends upward again (significantly). Happy times have returned.</li> </ul> <p>Obviously this is a very simplistic look at the album, and its emotional impact: lyrics, harmony, production, they all matter. But still, there’s something striking about seeing the arc of her career emerge from the raw numbers. By weighting the most powerful sung moments, we get a sense of where the “centre of gravity” of each album lies.</p> <p>And it turns out that when Taylor sings her life, the data sings it back.</p> <hr/> <p>Note: If you would like to try this yourself (inc. for other artists) <a href="/assets/code/taylor_swift.py">here is the link</a>, to the code I used to make this post. You just need to pass a folder of music files to the code and it will work out the rest for you.</p>]]></content><author><name></name></author><category term="mathematics"/><category term="code"/><summary type="html"><![CDATA[Taylor Swift doesn't just release albums, she releases chapters of her life, but can we see that story in the music itself?]]></summary></entry><entry><title type="html">Pour Over Brewing Recipe Generator</title><link href="https://seanelvidge.github.io/articles/2025/Pour_over_brewing_recipe_generator/" rel="alternate" type="text/html" title="Pour Over Brewing Recipe Generator"/><published>2025-03-31T18:41:00+00:00</published><updated>2025-03-31T18:41:00+00:00</updated><id>https://seanelvidge.github.io/articles/2025/Pour_over_brewing_recipe_generator</id><content type="html" xml:base="https://seanelvidge.github.io/articles/2025/Pour_over_brewing_recipe_generator/"><![CDATA[<p>I recently purchased a <a href="https://amzn.to/4j7ni2U">Fellow Aiden Precision Coffee Maker</a> which is a pour over coffee brewer. Able to brew individual cups to whole batches this machine is fantastic, and gives you complete control of the recipe it uses. From the bloom time and temperature to the number of pulses and the ability to control the temperature of each individual pulse.</p> <p>There are a number of default reciepes included and through the <a href="https://fellowproducts.com/pages/fellow-drops">Fellow Drops</a> programme you can get a number of tuned recipes for those coffees. Whilst, at the end of the day, coffee all coems down to personal preference, and any provided reciepe will need fine tuning, there are some fundamentals which provide a good starting point. To try and capture that information I have made the following recipe generator:</p> <p><a href="https://seanelvidge.com/brewcoffee">seanelvidge.com/brewcoffee</a></p> <p>If you visit that page, with the details of the coffee bean you have, you can have a look at what the reciepe generator says you should use. If you would like (a lot) more detail of the decisions that I have made to create the generator then read on.</p> <h1 id="roast-level-adjustments">Roast Level Adjustments</h1> <p>Roast level significantly influences extraction dynamics. Light roasts, dense and less porous, require extended blooming (initial wetting) and multiple pulses of hot water at precise intervals to fully unlock their flavors. Consequently, the recipe defaults for light roasts feature higher bloom ratios and longer bloom times, ensuring sufficient CO₂ release for consistent extraction.</p> <p>Conversely, dark roasts, due to their brittleness and faster extraction tendency, need lower extraction ratios and fewer pulses to avoid bitterness. The recipe parameters for darker roasts emphasize shorter bloom times and higher initial bloom temperatures to develop complexity without over-extraction.</p> <h3 id="specifics">Specifics</h3> <p>Light Roast:</p> <ul> <li>Brew Ratio: Increased to 17 for lighter body.</li> <li>Bloom Ratio: Increased to 3.5 to aid degassing.</li> <li>Bloom Time: Extended to 60 seconds for thorough extraction.</li> <li>Pulse Count: Increased to 6, ensuring complete flavor extraction.</li> </ul> <p>Dark Roast:</p> <ul> <li>Brew Ratio: Reduced to 15 to intensify body and reduce bitterness.</li> <li>Bloom Ratio: Decreased to 1.5 due to easier extraction.</li> <li>Bloom Time: Shortened to 40 seconds to prevent over-extraction.</li> <li>Pulse Count: Reduced to 3, limiting extraction bitterness.</li> </ul> <h1 id="bean-origin-influence">Bean Origin Influence</h1> <p>Beans from different regions exhibit unique physical traits influencing their extraction behavior. East African coffees, typically denser with higher solubility, require gentler bloom phases—lower ratios, shorter times, and reduced temperatures—to mitigate over-extraction and accentuate their bright, vibrant acidity.</p> <p>Latin American coffees often demand a longer bloom and higher temperatures to thoroughly degas and enhance sweetness and body. Indonesian coffees, known for their robust character, are best extracted with moderate bloom parameters that balance intensity with clarity.</p> <h3 id="specifics-1">Specifics</h3> <p>East African (Ethiopia, Kenya, etc.):</p> <ul> <li>Bloom Ratio: Decreased by 0.5 to minimize over-extraction.</li> <li>Bloom Time: Shortened by 5 seconds.</li> <li>Bloom Temperature: Reduced by 3°C.</li> <li>Pulse Count: Decreased by 1 to control acidity.</li> </ul> <p>Latin American (Brazil, Colombia, Guatemala):</p> <ul> <li>Bloom Ratio: Increased by 0.5 for effective degassing.</li> <li>Bloom Time: Increased by 5 seconds.</li> <li>Bloom Temperature: Raised by 3°C.</li> <li>Pulse Count: Increased by 1 to promote even extraction.</li> </ul> <p>Indonesian (Sumatra, Java):</p> <ul> <li>Bloom Ratio set to 2.5, Bloom Time standardized at 50 seconds.</li> <li>Pulse Count: Increased by 1 to maximize extraction clarity.</li> </ul> <h1 id="altitude-considerations">Altitude Considerations</h1> <p>High-altitude coffees, denser due to slower maturation, need more aggressive extraction parameters—finer grind, stronger brew ratios, and longer bloom durations—to achieve optimal flavor development. In contrast, lower-altitude beans benefit from coarser grinds and gentler extraction processes to preserve balance and avoid bitterness.</p> <h3 id="specifics-2">Specifics</h3> <p>High Altitude (&gt;1500m):</p> <ul> <li>Brew Ratio: Reduced by 0.5 for stronger extraction.</li> <li>Bloom Ratio: Increased by 0.5 to assist degassing.</li> <li>Bloom Time: Increased by 5 seconds.</li> <li>Grind Size: Finer by 2 increments.</li> </ul> <p>Low Altitude (&lt;1200m):</p> <ul> <li>Brew Ratio: Increased by 0.5 for gentler extraction.</li> <li>Bloom Ratio: Decreased by 0.5.</li> <li>Bloom Time: Reduced by 5 seconds.</li> <li>Grind Size: Coarser by 2 increments.</li> </ul> <h1 id="processing-method-adjustments">Processing Method Adjustments</h1> <p>Processing significantly impacts bean composition. Natural, honey, and anaerobic coffees, rich in sugars, require longer bloom periods and additional pulses to evenly extract these complex flavors. Washed coffees, typically cleaner and less dense, are best brewed with shorter blooms and fewer pulses, maintaining clarity and brightness.</p> <h3 id="specifics-3">Specifics</h3> <p>Natural, Honey, Carbonic, Anaerobic:</p> <ul> <li>Bloom Ratio: Increased by 0.5 (minimum of 2.5).</li> <li>Bloom Time: Extended by 5 seconds (minimum of 45 seconds).</li> <li>Pulse Count: Increased by 1 to control extraction consistency.</li> </ul> <p>Washed, Double Fermentation, Wet-Hulled:</p> <ul> <li>Bloom Ratio: Decreased by 0.5.</li> <li>Bloom Time: Reduced by 5 seconds.</li> <li>Pulse Count: Decreased by 1.</li> </ul> <h1 id="freshness-factor">Freshness Factor</h1> <p>The age of roasted coffee profoundly affects extraction due to CO₂ levels. Freshly roasted beans (0-7 days) release considerable CO₂, necessitating increased bloom water ratios, longer bloom times, and finer grinds to ensure thorough extraction without bitterness. Conversely, older beans (&gt;20 days) benefit from shorter blooms, lower temperatures, and coarser grinds to avoid over-extraction and maintain desirable flavors.</p> <h3 id="specifics-4">Specifics</h3> <p>Fresh Coffee (0–7 days):</p> <ul> <li>Bloom Ratio: Increased by 0.5.</li> <li>Bloom Time: Extended by 5 seconds.</li> <li>Grind Size: Finer by 4 increments.</li> <li>Pulse temperatures decreased by 1°C per pulse to counter CO₂ resistance.</li> </ul> <p>Older Coffee (&gt;20 days):</p> <ul> <li>Bloom Ratio: Decreased by 0.5.</li> <li>Bloom Time: Reduced by 5 seconds.</li> <li>Grind Size: Coarser by 4 increments.</li> <li>Pulse temperatures increased by 1°C per pulse to improve extraction.</li> </ul> <h1 id="flavor-profile-targeting">Flavor Profile Targeting</h1> <p>Achieving specific tasting notes requires fine-tuning extraction parameters:</p> <ul> <li>Fruity and acidic notes: Higher temperatures and finer grinds enhance bright flavors.</li> <li>Nutty and chocolatey notes: Richer bodies are cultivated through lower brew ratios and coarser grinds.</li> <li>Floral and herbal notes: Delicate aromatics emerge clearly with increased bloom ratios.</li> <li>Sweet and heavy notes: Lower bloom ratios preserve syrupy, sweet profiles.</li> <li>Creamy textures: Lower temperatures ensure smooth, rounded mouthfeels.</li> </ul> <h3 id="specifics-5">Specifics</h3> <p>Fruity/Acidic Notes:</p> <ul> <li>Brew Ratio: Increased by 0.5 for brightness.</li> <li>Bloom Temperature: Raised by 2°C.</li> <li>Grind Size: Finer by 4 increments.</li> </ul> <p>Nutty/Chocolate Notes:</p> <ul> <li>Brew Ratio: Decreased by 0.5 for richer body.</li> <li>Grind Size: Coarser by 2 increments.</li> </ul> <p>Floral/Herbal Notes:</p> <ul> <li>Bloom Ratio: Increased by 0.5 for aromatic extraction.</li> <li>Grind Size: Coarser by 2 increments.</li> </ul> <p>Heavy Sweet Notes:</p> <ul> <li>Bloom Ratio: Reduced by 0.5 for syrupy texture.</li> <li>Grind Size: Finer by 2 increments.</li> </ul> <p>Creamy Notes:</p> <ul> <li>Bloom Temperature: Reduced by 2°C to preserve smoothness.</li> </ul> <h1 id="pulse-temperature-profiles">Pulse Temperature Profiles</h1> <p>Dynamic pulse temperatures optimize extraction across roast levels:</p> <ul> <li>Light roasts gradually increase temperature across pulses, enhancing complexity.</li> <li>Medium roasts maintain stable temperatures for balanced extraction.</li> <li>Dark roasts reduce temperatures progressively to avoid bitterness, enhancing depth.</li> </ul> <p>Final pulse temperatures further adjust to emphasize specific tasting notes—higher initial temperatures highlight bright, fruity notes, while lower final temperatures preserve sweetness and depth.</p> <h3 id="specifics-6">Specifics</h3> <p>Light Roasts: Gradually increase temperature from 90°C to 96°C.</p> <p>Medium Roasts: Maintain stable bloom temperature; adjust slightly for anaerobic or carbonic processes.</p> <p>Dark Roasts: Decrease temperature progressively from 91°C to 85°C to minimize bitterness.</p> <h1 id="conclusion">Conclusion</h1> <p>The <a href="https://amzn.to/4j7ni2U">Fellow Aiden Precision Coffee Maker</a> is a great coffee brewer, giving you almost complete control of the brewing process. You can access the recipe generator here:</p> <p><a href="https://seanelvidge.com/brewcoffee">seanelvidge.com/brewcoffee</a></p>]]></content><author><name></name></author><category term="misc"/><summary type="html"><![CDATA[Generate pour over brewing coffee reciepes for a given bean]]></summary></entry><entry><title type="html">Waning Home Advantage in English League Football</title><link href="https://seanelvidge.github.io/articles/2025/Home_advantage_in_English_football/" rel="alternate" type="text/html" title="Waning Home Advantage in English League Football"/><published>2025-01-13T09:00:00+00:00</published><updated>2025-01-13T09:00:00+00:00</updated><id>https://seanelvidge.github.io/articles/2025/Home_advantage_in_English_football</id><content type="html" xml:base="https://seanelvidge.github.io/articles/2025/Home_advantage_in_English_football/"><![CDATA[<p>For generations, “home advantage” has been a tenet of sports. The roar of the crowd, the familiarity of the pitch, the comfort of the home dressing room – all give the home team an edge. This is particularly true in English football. However, a look at the data spanning over a century of English football reveals an interesting trend: the home advantage is shrinking.</p> <p>Using my database of all English league results since 1888 (available <a href="https://github.com/seanelvidge/England-football-results">here</a>, and described <a href="https://seanelvidge.com/articles/2024/All_England_football_league_results/">here</a>) we can track the Home Win %, Draw %, and Away Win % from 1888 to the present day (at the time of writing, that is halfway through the 2024/2025 season, but the charts in this post should automatically update). The results are pretty clear:</p> <html> <div class="chart-container"> <canvas id="resultsChart"></canvas> </div> <img id="fallbackImage1" src="assets/img/home_advantage_trend_fallback.png" alt="Fallback image for home, draw, away % win" style="display: none; max-width: 100%;"/> <style>.chart-container{position:relative;width:100%;min-height:250px;height:50vh;max-height:80vh}</style> </html> <p>In the late 19th and early 20th centuries, home teams were dominant, boasting win percentages well above 60%. Away wins were a relative rarity, hovering around 20%. But as the decades have progressed, the lines have converged. Home win percentages have steadily declined, dipping towards 40% in recent years, while away wins have climbed, now consistently above 30% and with a clear upwards trajectory.</p> <p>It would be easy to assume that this trend is confined to the top tier of English football, where the largest investments in training facilities, player recruitment, and tactical analysis occur. However, if we look at the home win percentages across all four tiers of English football (where “Tier 1” is the highest tier, currently the Premier League and “Tier 4” is the lowest, EFL League Two) we can see that this is a league-wide phenomenon.</p> <html> <div class="chart-container"> <canvas id="divisionChart"></canvas> </div> <img id="fallbackImage2" src="assets/img/home_advantage_trend_fallback_by_division.png" alt="Fallback image for home win % by division" style="display: none; max-width: 100%;"/> </html> <p>As you can see, the decline in home win percentages is remarkably consistent across all levels of professional English football. While there are some minor variations between divisions, the overall trajectory is the same: downwards. This suggests that the factors driving the change are not unique to the top tier but are systemic throughout the entire football pyramid. Each division shows high home win % at the start of the time series (above 50%), but each division ends up closer to 40% by the end of the series.</p> <p>So, what’s driving this shift away from home dominance? Several factors are likely at play:</p> <ul> <li>Standardization of Playing Conditions: In the early days, pitch conditions varied wildly. Home teams were intimately familiar with their own, often quirky, pitches, giving them a distinct advantage. Over time, regulations and advancements in groundskeeping have led to more standardized, high-quality pitches across the league, leveling the playing field. This impact would be felt across all divisions.</li> <li>Improved Travel and Accommodation: Early football often involved arduous journeys for away teams, leaving them fatigued and less prepared. Modern transportation and improved accommodations have minimized the physical toll of travel, allowing away teams to arrive rested and ready to compete. Again, this is relevant to all levels of the game.</li> <li>Tactical Advancements and Analysis: The modern game is far more tactically sophisticated. Managers and analysts have access to vast amounts of data and video footage, allowing them to dissect opponents’ strengths and weaknesses, regardless of location. Away teams can now better prepare for the specific challenges posed by their opponents and their home stadiums. While the resources may be greater at the top, these advancements have filtered down through the divisions.</li> <li>Professionalization and Fitness: Players today are fitter, faster, and more technically skilled than ever before. This overall increase in athleticism can help away teams better cope with the pressures of playing in hostile environments, a trend seen across the footballing spectrum.</li> </ul> <h2 id="the-future-of-home-advantage">The Future of Home Advantage</h2> <p>Whilst home advantage may not be what it once was, it hasn’t disappeared entirely. The support of the home crowd can still provide a boost, and familiarity with the surroundings can offer a slight edge. However, the trend is undeniable. The gap between home and away performance is narrowing, and the English Football League, across all its divisions, is becoming increasingly competitive on all fronts.</p> <p>If we look to extrapolate the trends in the data we can try and estimate what will happen in the future, fitting lines of best fit to the data we can estimate that home advantage will stick around for quite a while yet!</p> <div class="chart-container"> <canvas id="finalTrendChart"></canvas> </div> <html> <script src="https://cdn.jsdelivr.net/npm/papaparse@5.3.0/papaparse.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/chart.js"></script> <script src="https://cdn.jsdelivr.net/npm/chartjs-plugin-zoom"></script> <script>function showFallbackImages(){document.getElementById("resultsChart").style.display="none",document.getElementById("divisionChart").style.display="none",document.getElementById("fallbackImage1").style.display="block",document.getElementById("fallbackImage2").style.display="block"}function processData(t){const e={},a={};t.forEach(t=>{if(!t.Season||!t.Result)return;const o=t.Season,s=t.Tier,n=t.Result;e[o]||(e[o]={H:0,D:0,A:0,total:0}),e[o][n]++,e[o].total++,a[o]||(a[o]={}),s&&!a[o][s]&&(a[o][s]={H:0,D:0,A:0,total:0}),s&&(a[o][s][n]++,a[o][s].total++)});const o=Object.keys(e).sort().pop(),s=calculatePercentages(e,o),n=calculateDivisionPercentages(a);createResultsChart(s),createDivisionChart(n),createFinalTrendChart(s)}function calculatePercentages(t,e){const a=Object.keys(t).sort(),o=[],s=[],n=[],l=[],r=[],i=[],c=[];return a.forEach(a=>{const d=t[a],u=d.total,p=parseFloat((d.H/u*100).toFixed(2)),h=parseFloat((d.D/u*100).toFixed(2)),b=parseFloat((d.A/u*100).toFixed(2)),g=calculateStandardDeviation(d.H,u),f=calculateStandardDeviation(d.D,u),C=calculateStandardDeviation(d.A,u);a&&a<=e&&(c.push(a),o.push(p),s.push(h),n.push(b),l.push(g),r.push(f),i.push(C))}),{labels:c,datasets:[{label:"Home Win %",data:o,borderColor:"blue",backgroundColor:"transparent"},{label:"Draw %",data:s,borderColor:"green",backgroundColor:"transparent"},{label:"Away Win %",data:n,borderColor:"red",backgroundColor:"transparent"}]}}function calculateDivisionPercentages(t){const e=Object.keys(t).sort(),a={};return e.forEach(e=>{Object.keys(t[e]).forEach(o=>{if(o&&!a[o]){let t;t="1"===o?"red":"2"===o?"blue":"3"===o?"green":"4"===o?"purple":getRandomColor(),a[o]={label:`Division ${o}`,data:[],borderColor:t,backgroundColor:"transparent",errorBars:[]}}if(o){const s=t[e][o],n=s.total,l=parseFloat((s.H/n*100).toFixed(2));parseFloat((s.D/n*100).toFixed(2)),parseFloat((s.A/n*100).toFixed(2));a[o].data.push({x:e,y:l}),a[o].errorBars.push(calculateStandardDeviation(s.H,n))}})}),{labels:e,datasets:Object.values(a)}}function getRandomColor(){const t="0123456789ABCDEF";let e="#";for(let a=0;a<6;a++)e+=t[Math.floor(16*Math.random())];return e}function calculateStandardDeviation(t,e){const a=t/e;return 100*Math.sqrt(a*(1-a)/e)}function createResultsChart(t){const e=document.getElementById("resultsChart").getContext("2d");resultsChart=new Chart(e,{type:"line",data:t,options:{maintainAspectRatio:!1,plugins:{legend:{labels:{usePointStyle:!0}},zoom:{zoom:{wheel:{enabled:!1},pinch:{enabled:!0},mode:"xy"}},tooltip:{callbacks:{label:function(t){let e=t.dataset.label||"";return e&&(e+=": "),e+=Number(t.parsed.y).toFixed(1)+"%",e},footer:function(t){t[0].dataset}}}},scales:{y:{beginAtZero:!0,title:{display:!0,text:"Percentage",font:{size:16}},ticks:{font:{size:14}}},x:{ticks:{callback:function(t){const e=this.getLabelForValue(t);if(e.endsWith("5")||e.endsWith("0"))return e.substring(0,4)},font:{size:14}},title:{display:!0,text:"Season",font:{size:16}}}}}})}function createDivisionChart(t){const e=document.getElementById("divisionChart").getContext("2d");divisionChart=new Chart(e,{type:"line",data:t,options:{maintainAspectRatio:!1,plugins:{legend:{labels:{usePointStyle:!0}},zoom:{zoom:{wheel:{enabled:!1},pinch:{enabled:!0},mode:"xy"}},tooltip:{callbacks:{label:function(t){let e=t.dataset.label||"";return e&&(e+=": "),e+=Number(t.parsed.y).toFixed(1)+"%",e},footer:function(t){return`\xb1${t[0].dataset.errorBars[t[0].dataIndex].toFixed(2)}%`}}},title:{display:!0,text:"% Home Wins per Division"}},scales:{y:{beginAtZero:!0,title:{display:!0,text:"Percentage",font:{size:16}},ticks:{font:{size:14}}},x:{ticks:{callback:function(t){const e=this.getLabelForValue(t);if(e.endsWith("5")||e.endsWith("0"))return e.substring(0,4)},font:{size:14}},title:{display:!0,text:"Season",font:{size:16}}}}}})}function updateChartTheme(t){const e=t?"#242424":"#FFFFFF",a=t?"#FFFFFF":"#000000";resultsChart.options.plugins.legend.labels.color=a,resultsChart.options.scales.x.title.color=a,resultsChart.options.scales.x.ticks.color=a,resultsChart.options.scales.y.title.color=a,resultsChart.options.scales.y.ticks.color=a,resultsChart.options.backgroundColor=e,resultsChart.update(),divisionChart.options.plugins.legend.labels.color=a,divisionChart.options.scales.x.title.color=a,divisionChart.options.scales.x.ticks.color=a,divisionChart.options.scales.y.title.color=a,divisionChart.options.scales.y.ticks.color=a,divisionChart.options.backgroundColor=e,divisionChart.update()}const resultsUrl="https://raw.githubusercontent.com/seanelvidge/England-football-results/main/EnglandLeagueResults.csv";let resultsChart,divisionChart;Papa.parse(resultsUrl,{download:!0,header:!0,dynamicTyping:!0,skipEmptyLines:!0,complete:function(t){if(!t||!t.data||0===t.data.length)return console.warn("No valid data returned. Showing fallback images."),void showFallbackImages();if(t.errors&&t.errors.length>0)return console.warn("Papa Parse encountered errors. Showing fallback images:",t.errors),void showFallbackImages();processData(t.data)},error:function(t){console.error("Error loading remote data",t),showFallbackImages()}});</script> <script>function linearRegression(e,t){const a=e.length;let r=0,n=0,l=0,o=0;for(let s=0;s<a;s++)r+=e[s],n+=t[s],l+=e[s]*t[s],o+=e[s]*e[s];const s=(a*l-r*n)/(a*o-r*r);return{slope:s,intercept:(n-s*r)/a}}function createFinalTrendChart(e){function t(e,t){const a=parseInt(e.substring(0,4),10)+t;return`${a}-${a+1}`}const a=e.labels,r=a.map((e,t)=>t),n=e.datasets[0].data,l=e.datasets[1].data,o=e.datasets[2].data,s=linearRegression(r,n),d=linearRegression(r,l),i=linearRegression(r,o),c=r[r.length-1],b=[];for(let e=0;e<=c+50;e++)b.push(e);const u=b.map(e=>{if(e<=c)return a[e];{const r=e-c;return t(a[c],r)}}),p=[],g=[],h=[];for(let e=0;e<b.length;e++){const t=b[e],a=s.slope*t+s.intercept,r=d.slope*t+d.intercept,n=i.slope*t+i.intercept,l=a+r+n,o=a/l*100,c=r/l*100,u=n/l*100;p.push(o),g.push(c),h.push(u)}const f={labels:u,datasets:[{label:"Home Win %",data:e.datasets[0].data.concat(Array(b.length-r.length).fill(null)),borderColor:"blue",backgroundColor:"transparent"},{label:"Draw %",data:e.datasets[1].data.concat(Array(b.length-r.length).fill(null)),borderColor:"green",backgroundColor:"transparent"},{label:"Away Win %",data:e.datasets[2].data.concat(Array(b.length-r.length).fill(null)),borderColor:"red",backgroundColor:"transparent"},{label:"Home Trend (Normalized)",data:p,borderColor:"blue",backgroundColor:"transparent",borderDash:[5,5],pointRadius:0},{label:"Draw Trend (Normalized)",data:g,borderColor:"green",backgroundColor:"transparent",borderDash:[5,5],pointRadius:0},{label:"Away Trend (Normalized)",data:h,borderColor:"red",backgroundColor:"transparent",borderDash:[5,5],pointRadius:0}]},C=document.getElementById("finalTrendChart").getContext("2d");finalTrendChart=new Chart(C,{type:"line",data:f,options:{maintainAspectRatio:!1,scales:{y:{beginAtZero:!0,title:{display:!0,text:"Percentage",font:{size:16}},ticks:{font:{size:14}}},x:{ticks:{font:{size:14},callback:function(e,t){return t%5==0?this.getLabelForValue(e):""}},title:{display:!0,text:"Season",font:{size:16}}}},plugins:{title:{display:!1,text:"Home/Draw/Away % with Normalized Trend to 100%"},tooltip:{callbacks:{label:function(e){let t=e.dataset.label||"";return t&&(t+=": "),t+=Number(e.parsed.y).toFixed(1)+"%",t}}},legend:{labels:{usePointStyle:!0}},zoom:{zoom:{wheel:{enabled:!1},pinch:{enabled:!0},mode:"xy"}}}}})}let finalTrendChart;</script> </html>]]></content><author><name></name></author><category term="football"/><summary type="html"><![CDATA[An investigation in the trend of home advantage in English football]]></summary></entry></feed>