<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://seanelvidge.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://seanelvidge.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-11-20T22:02:35+00:00</updated><id>https://seanelvidge.github.io/feed.xml</id><title type="html">Sean Elvidge</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Levelling the Playing Field, Adjusting Goal Records in International Football</title><link href="https://seanelvidge.github.io/blog/2024/Adj_Eng_Goals/" rel="alternate" type="text/html" title="Levelling the Playing Field, Adjusting Goal Records in International Football"/><published>2024-11-20T17:13:00+00:00</published><updated>2024-11-20T17:13:00+00:00</updated><id>https://seanelvidge.github.io/blog/2024/Adj_Eng_Goals</id><content type="html" xml:base="https://seanelvidge.github.io/blog/2024/Adj_Eng_Goals/"><![CDATA[<p>In recent years, we’ve witnessed a surge in international football records being shattered. Modern players are scoring at unprecedented rates, and while this is undoubtedly exciting for fans, it raises an important question: Are today’s goal-scoring feats truly comparable to those of past legends?</p> <p>The landscape of international football has evolved significantly. The expansion of FIFA membership has introduced many new, smaller nations into the competitive arena. This influx has led to more matches where traditional football powerhouses face off against developing teams, often resulting in lopsided scorelines. Consequently, contemporary players have more opportunities to inflate their goal tallies against weaker opposition.</p> <p>This shift poses a challenge when attempting to compare the goal-scoring records of current players with those from previous eras. The legends of the past often played fewer matches against a more consistent level of competition, making their goal tallies a reflection of performances against relatively equal opponents.</p> <p>So, how can we level the playing field and make fair comparisons across different football eras?</p> <h2 id="introducing-a-weighted-goal-system">Introducing a Weighted Goal System</h2> <p>To address this disparity, I embarked on a project to adjust goal records by accounting for the relative strength of the opposition. The idea is to assign a weighting to each goal based on the difficulty of scoring against a particular team at the time of the match. This method aims to provide a more nuanced evaluation of a player’s goal-scoring achievements.</p> <h3 id="utilizing-elo-ratings">Utilizing ELO Ratings</h3> <p>The foundation of this approach lies in the ELO rating system, a method originally devised for ranking chess players but now widely adopted across various sports, including football. ELO ratings provide a dynamic measure of a team’s strength, updating after each match based on the result and the quality of the opposition.</p> <p>By leveraging historical ELO ratings, we can assess the relative strength of any two teams at the time they played. This allows us to calculate a weighting factor for each goal scored, reflecting the challenge posed by the opponent.</p> <h3 id="the-weighting-formula">The Weighting Formula</h3> <p>The weighting for each goal is determined using the following formula:</p> \[\text{Weight} = 1 - k\times\frac{E-O}{E}\] <p>Where, $E$ is the ELO rating of England before the match, $O$ is the ELO rating of the opposition before the match and $k$ a scaling constant that adjusts the sensitivity of the weighting to the difference in ELO ratings.</p> <p>This formula adjusts the weight of a goal based on how much stronger or weaker the opposition is relative to England:</p> <ul> <li>If England faces a stronger team ($O &gt; E$), the weighting increases above 1, acknowledging the greater difficulty.</li> <li>If England faces a weaker team ($O &lt; E$), the weighting decreases below 1, reflecting the relatively easier challenge.</li> <li>The constant $k$ controls how much the difference in ratings affects the weighting.</li> </ul> <h3 id="interpreting-the-weighting">Interpreting the Weighting</h3> <p>Adjusting the $k$ value alters the impact of the opposition’s strength:</p> <ul> <li>A higher $k$ value (e.g., 2) amplifies the effect, giving more weight to goals against stronger teams and less to those against weaker ones.</li> <li>A lower $k$ value (e.g., 1) minimizes the effect, resulting in a more uniform weighting across different opponents.</li> </ul> <p>By experimenting with different $k$ values, we can fine-tune the system to balance fairness and sensitivity, ensuring that exceptional performances against top-tier teams are appropriately recognized while maintaining a reasonable value for consistent scoring against all opponents.</p> <p>For the rest of this post we use a value of $k=2$.</p> <h3 id="results">Results</h3> <p>When I last wrote a post similar to this, Wayne Rooney had just <a href="https://seanelvidge.github.io/blog/2015/Rooney-50/">broke the England National team goal record with 50 goals</a>. Since then Kane has broke this record again (at the time of writing) with 69 goals. Using the above approach the updated top 10 of England goal scorers are:</p> <table> <thead> <tr> <th style="text-align: center">Ranking</th> <th style="text-align: center">Name</th> <th style="text-align: center">Adjusted Goals</th> <th style="text-align: center">Goals</th> </tr> </thead> <tbody> <tr> <td style="text-align: center">1</td> <td style="text-align: center">Harry Kane</td> <td style="text-align: center">45</td> <td style="text-align: center">69</td> </tr> <tr> <td style="text-align: center">2</td> <td style="text-align: center">Gary Lineker</td> <td style="text-align: center">37</td> <td style="text-align: center">48</td> </tr> <tr> <td style="text-align: center">3</td> <td style="text-align: center">Bobby Charlton</td> <td style="text-align: center">36</td> <td style="text-align: center">49</td> </tr> <tr> <td style="text-align: center">4</td> <td style="text-align: center">Jimmy Greaves</td> <td style="text-align: center">35</td> <td style="text-align: center">44</td> </tr> <tr> <td style="text-align: center">5</td> <td style="text-align: center">Wayne Rooney</td> <td style="text-align: center">34</td> <td style="text-align: center">53</td> </tr> <tr> <td style="text-align: center">6</td> <td style="text-align: center">Michael Owen</td> <td style="text-align: center">30</td> <td style="text-align: center">40</td> </tr> <tr> <td style="text-align: center">7</td> <td style="text-align: center">Alan Shearer</td> <td style="text-align: center">23</td> <td style="text-align: center">30</td> </tr> <tr> <td style="text-align: center">8</td> <td style="text-align: center">Tom Finney</td> <td style="text-align: center">23</td> <td style="text-align: center">30</td> </tr> <tr> <td style="text-align: center">9</td> <td style="text-align: center">Nat Lofthouse</td> <td style="text-align: center">22</td> <td style="text-align: center">30</td> </tr> <tr> <td style="text-align: center">10</td> <td style="text-align: center">Frank Lampard</td> <td style="text-align: center">21</td> <td style="text-align: center">29</td> </tr> </tbody> </table> <p>You can see that whilst Kane is still number 1 - his number of goals are significantly less. (Note that the adjusted number of goals here have been rounded to the nearest goal for ease of reading).</p> <p>As may be expected Kane has the biggest change between actual goals scored (69) and the weighted number of goals (45) with a difference of 24, perphaps reaffirming the theory that modern day players are scoring a significant amount of their goals against weaker opposition than in the past. Gary Lineker moves from 4th in the all time list to 2nd.</p> <p>At the other end of the table we end up with a number of people (41) who (because of the rounding as well) move from having scored at least 1 for England to being on 0 goals, but only four who go from more than 1 to zero:</p> <table> <thead> <tr> <th style="text-align: center">Name</th> <th style="text-align: center">Goals</th> <th style="text-align: center">Adjusted Goals</th> </tr> </thead> <tbody> <tr> <td style="text-align: center">Tammy Abraham</td> <td style="text-align: center">3</td> <td style="text-align: center">0</td> </tr> <tr> <td style="text-align: center">Paul Ince</td> <td style="text-align: center">2</td> <td style="text-align: center">0</td> </tr> <tr> <td style="text-align: center">Tyrone Mings</td> <td style="text-align: center">2</td> <td style="text-align: center">0</td> </tr> <tr> <td style="text-align: center">James Ward-Prowse</td> <td style="text-align: center">2</td> <td style="text-align: center">0</td> </tr> </tbody> </table> <p>Unfortuntaely Tammy Abraham’s 3 goals for England were scored against very much weaker opposition in the form of Montenegro (England won 7-0 on 14/11/19), Andorra (England won 0-5 on 09/10/21) and San Marino (England won 0-10 on 15/11/21).</p> <p>If you want to have a look at the data you can access it all <a href="https://seanelvidge.github.io/assets/files/england_elo_goal_data.csv">here</a>) (which also includes the “Adjusted Total” which weights Friendlies as 0.5 and “finals” as 2x (as per the description <a href="https://seanelvidge.github.io/blog/2015/Rooney-50/">here</a>.</p>]]></content><author><name></name></author><category term="mathematics"/><category term="football"/><summary type="html"><![CDATA[By weighting international goals by strength of the opposition we can compare goal scoring prowess across the decades.]]></summary></entry><entry><title type="html">Correlation between Astronaut name and Apollo mission</title><link href="https://seanelvidge.github.io/blog/2015/Apollo_Astro_Corr/" rel="alternate" type="text/html" title="Correlation between Astronaut name and Apollo mission"/><published>2015-12-15T18:25:00+00:00</published><updated>2015-12-15T18:25:00+00:00</updated><id>https://seanelvidge.github.io/blog/2015/Apollo_Astro_Corr</id><content type="html" xml:base="https://seanelvidge.github.io/blog/2015/Apollo_Astro_Corr/"><![CDATA[<p>Python’s <code class="language-plaintext highlighter-rouge">matplotlib</code> includes the impressive <code class="language-plaintext highlighter-rouge">XKCDify</code> feature, which allows plots to resemble Randall Munroe’s style from <a href="https://xkcd.com">xkcd.com</a>.<br/> Upon discovering this feature (<code class="language-plaintext highlighter-rouge">matplotlib.pyplot.xkcd()</code>), I sought a creative application beyond replicating classic XKCD plots like <a href="https://xkcd.com/653">xkcd.com/653</a> and <a href="https://xkcd.com/1220">xkcd.com/1220</a>.</p> <p>Deke Slayton, the chief astronaut, selected the crews for the Apollo and Gemini missions, the exact process he used has been somewhat mysterious…</p> <p>One day, while walking to work, I recalled that Armstrong, Aldrin, and Collins were on Apollo 11—all near the beginning of the alphabet. Similarly, Conrad and Bean were on Apollo 12 (though I couldn’t recall the third crew member at that moment). I also remembered Lovell and Haise from Apollo 13, Shepard from Apollo 14, and Young from Apollo 16. This led me to consider that alphabetical order might have ‘influenced’ crew assignments.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/apollo_az-480.webp 480w,/assets/img/apollo_az-800.webp 800w,/assets/img/apollo_az-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/apollo_az" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Hey look! Clearly the order was, at least partially, determined alphabetically.</p> <p>Or perhaps not? This observation brings us to the topic of confidence intervals, which are crucial in statistical analysis. While strong correlations can be found between various factors, this doesn’t necessarily imply causation. For instance, there’s a 0.985 correlation between arcade revenue and computer science doctorates awarded in the U.S. (More examples can be found at <a href="https://tylervigen.com/spurious-correlations">tylervigen.com/spurious-correlations</a>.)<br/> Even ignoring causation, one thing we should consider is the confidence interval of our correlation.</p> <p>Confidence intervals indicate the reliability of a statistical measure; more data typically leads to greater trust in the result. These intervals are often specified at levels like 95% or 99%.</p> <p>Let’s examine a simple example, calculating a 95% confidence interval for a percentage:</p> <p>A TV advertisement claimed that a certain hair conditioner is the nation’s favorite, with small print stating, “73% of 64 people asked agreed.” This means 47 people concurred (0.73 × 64 ≈ 47). A larger sample size would provide more confidence in this claim. However, we can use the confidence interval to assess the statistical significance of 73% from a sample of 64. The formula for a 95% confidence interval of a percentage is:</p> \[95\text{\%} \text{ C.I.} = \pm 1.96 \times \sqrt{\frac{p(1-p)}{n}}\] <p>where $p$ is the percentage (as a decimal) and $n$ is the sample size. Applying our numbers:</p> \[\begin{align*} 95\text{\% C.I.} &amp;= \pm 1.96 \times \sqrt{\frac{0.73 \times 0.27}{64}} \\ &amp;= \pm 10.9 \end{align*}\] <p>This results in a 95% confidence interval of approximately $\pm$11%, indicating that the true percentage likely falls between 62% and 84%. This technique is valuable when evaluating data; always consider confidence intervals to determine the reliability of a result.</p> <p>In our case, the correlation coefficient between alphabetical ordering and Apollo astronauts is 0.45, suggesting a moderate positive correlation. However, it’s essential to examine the confidence interval for this correlation. Calculating confidence intervals for correlations is more complex and often asymmetric. Detailed information on this topic is available at <a href="https://onlinestatbook.com/2/estimation/correlation_ci.html">onlinestatbook.com</a>. For our data, the confidence interval ranges from 0.023 to 0.738, spanning from no correlation to a strong one.</p> <p>Therefore, it’s uncertain whether we’ve uncovered Deke’s method or not.</p> <p>The key takeaway is the importance of considering confidence intervals in statistical analysis.</p> <p>For those interested, here’s the <a href="../assets/code/apollo_astronaut_az.py">code used to create the plot</a>, which can serve as a starting point for experimenting with <code class="language-plaintext highlighter-rouge">plt.xkcd()</code>.</p>]]></content><author><name></name></author><category term="mathematics"/><summary type="html"><![CDATA[Perhaps we’ve finally worked out Deke Slayton's method for choosing the Apollo crews, basing it on alphabetical order…]]></summary></entry><entry><title type="html">Rooney Scores 50 goals for England – the data</title><link href="https://seanelvidge.github.io/blog/2015/Rooney-50/" rel="alternate" type="text/html" title="Rooney Scores 50 goals for England – the data"/><published>2015-09-11T23:46:00+00:00</published><updated>2015-09-11T23:46:00+00:00</updated><id>https://seanelvidge.github.io/blog/2015/Rooney-50</id><content type="html" xml:base="https://seanelvidge.github.io/blog/2015/Rooney-50/"><![CDATA[<p>Wayne Rooney has broken the England football goal scoring record with 50 goals. A lot of discussion has therefore been about if he is the greatest English attacker of all time or not. Let’s look at the data.</p> <p>The main argument against Rooney being the greatest is his lack of World Cup Finals goals (1; at the 2014 finals). A comment which is also often made is about the number of “friendly” goals scored. Lineker (with a total of 48 goals for England, 3rd in the all time list) was recently voted as England’s greatest attacker in a BBC poll, managed 10 goals in World Cup finals (including the 1986 Golden Boot).</p> <p>So what if we weight goals differently? What if we make friendly goals worth 0.5 a goal, and “finals” goals (i.e. the World Cup Finals and European Championships Finals) as times 2? What does that do to the all time scoring list?</p> <p>(Here I count goals in the old “Home Championship” as ‘1’ (i.e. the same as World Cup and European qualifiers). Although there is an argument to be had that it should be weighted more heavily since it was <strong>the</strong> international competition for England before the World Cup got “big” (~pre-1950s). However, for now I’ll leave its weighting as ‘1’.)</p> <p>In that adjusted table we get the following:</p> <table> <thead> <tr> <th style="text-align: center">Ranking</th> <th style="text-align: center">Name</th> <th style="text-align: center">Adjusted Goals</th> </tr> </thead> <tbody> <tr> <td style="text-align: center">1</td> <td style="text-align: center">Wayne Rooney</td> <td style="text-align: center">49</td> </tr> <tr> <td style="text-align: center">2</td> <td style="text-align: center">Gary Lineker</td> <td style="text-align: center">46</td> </tr> <tr> <td style="text-align: center">3</td> <td style="text-align: center">Bobby Charlton</td> <td style="text-align: center">43</td> </tr> <tr> <td style="text-align: center">4</td> <td style="text-align: center">Michael Owen</td> <td style="text-align: center">39</td> </tr> <tr> <td style="text-align: center">5</td> <td style="text-align: center">Jimmy Greaves</td> <td style="text-align: center">34.5</td> </tr> <tr> <td style="text-align: center">5</td> <td style="text-align: center">Alan Shearer</td> <td style="text-align: center">34. 5</td> </tr> </tbody> </table> <p>You can see that Rooney is still number 1 - despite down weighting the friendly goals.</p> <p>But okay, perhaps you think friendlies shouldn’t count at all and only competitive fixtures should be counted (the ‘Adjusted Goals’ column is if we again weight finals goals more heavily, the first ranking column is for the ‘non-adjusted’ goals):</p> <table> <thead> <tr> <th style="text-align: center">Ranking</th> <th style="text-align: center">Name</th> <th style="text-align: center">Goals</th> <th style="text-align: center">Adjusted Goals</th> <th style="text-align: center">Adjusted Ranking</th> </tr> </thead> <tbody> <tr> <td style="text-align: center">1</td> <td style="text-align: center">Wayne Rooney</td> <td style="text-align: center">36</td> <td style="text-align: center">42</td> <td style="text-align: center">1</td> </tr> <tr> <td style="text-align: center">2</td> <td style="text-align: center">Stephen Bloomer</td> <td style="text-align: center">28</td> <td style="text-align: center">28</td> <td style="text-align: center">6</td> </tr> <tr> <td style="text-align: center">3</td> <td style="text-align: center">Bobby Charlton</td> <td style="text-align: center">27</td> <td style="text-align: center">32</td> <td style="text-align: center">3</td> </tr> <tr> <td style="text-align: center">4</td> <td style="text-align: center">Michael Owen</td> <td style="text-align: center">26</td> <td style="text-align: center">32</td> <td style="text-align: center">3</td> </tr> <tr> <td style="text-align: center">5</td> <td style="text-align: center">Gary Lineker</td> <td style="text-align: center">24</td> <td style="text-align: center">34</td> <td style="text-align: center">2</td> </tr> <tr> <td style="text-align: center">6</td> <td style="text-align: center">Jimmy Greaves</td> <td style="text-align: center">23</td> <td style="text-align: center">24</td> <td style="text-align: center">8</td> </tr> </tbody> </table> <p>Again, Rooney comes top for both the usual and adjusted goal tallies. (One way) to knock Rooney off that top spot (if you particularly want to for some reason) is to look at the ‘goals per cap ratio’. To use this stat we have to set a cap limit because of the people who didn’t play very much. For example, Albert Allen, Francis Bradshaw, John Veitch, John Yates and Rev. Walter Gilliat who were all capped once by England, and each scored a hattrick on their one, and only, appearance for England. This gives them a rather impressive 3 goals per cap ratio. If we only consider players who have at least 40 caps then:</p> <table> <thead> <tr> <th style="text-align: center">Ranking</th> <th style="text-align: center">Name</th> <th style="text-align: center">Goals per cap</th> </tr> </thead> <tbody> <tr> <td style="text-align: center">1</td> <td style="text-align: center">Jimmy Greaves</td> <td style="text-align: center">0.77</td> </tr> <tr> <td style="text-align: center">2</td> <td style="text-align: center">Gary Lineker</td> <td style="text-align: center">0.6</td> </tr> <tr> <td style="text-align: center">3</td> <td style="text-align: center">Peter Crouch</td> <td style="text-align: center">0.52</td> </tr> <tr> <td style="text-align: center">4</td> <td style="text-align: center">Geoff Hurst</td> <td style="text-align: center">0.49</td> </tr> <tr> <td style="text-align: center">5</td> <td style="text-align: center">Alan Shearer</td> <td style="text-align: center">0.48</td> </tr> <tr> <td style="text-align: center">6</td> <td style="text-align: center">Wayne Rooney</td> <td style="text-align: center">0.47</td> </tr> </tbody> </table> <p>Finally, if you again weighted the goals (since Crouch scored 12 of his 22 goals in friendlies) you would find the order is Greaves, Lineker, Hurst, Shearer, Rooney (Crouch drops from 3rd to 8th).</p> <p>I am not going to make any conclusions about if Rooney is England’s greatest attacker or not, that is up to you! All the data I’ve used in this post was collected from <a href="https://www.englandstats.com/">englandstats.com</a> and is accurate as of today (11th September, 2015). If you want to play around with the data I’ve collated all the stats (player names, caps, minutes played and goals scored (separated into individual competitions)) into an Excel file available <a href="https://seanelvidge.github.io/assets/files/england_goal_data_2015_09_11.xlsx">here</a>.</p> <h2 id="update">Update</h2> <p>An updated data file, as of 2024-11-20, is available <a href="https://seanelvidge.github.io/assets/files/england_goal_data.csv">here</a>. This includes an ‘Adjusted Total’ column which, as above, weights friendly goals as 0.5 and “finals” goals (i.e. the World Cup Finals and European Championships Finals) by a factor of 2.</p>]]></content><author><name></name></author><category term="mathematics"/><category term="football"/><summary type="html"><![CDATA[Data analysis of Wayne Rooney's 50 goals for England]]></summary></entry><entry><title type="html">Safe Reboot of Locked Linux Machine</title><link href="https://seanelvidge.github.io/blog/2015/safe-reboot/" rel="alternate" type="text/html" title="Safe Reboot of Locked Linux Machine"/><published>2015-03-20T15:29:00+00:00</published><updated>2015-03-20T15:29:00+00:00</updated><id>https://seanelvidge.github.io/blog/2015/safe-reboot</id><content type="html" xml:base="https://seanelvidge.github.io/blog/2015/safe-reboot/"><![CDATA[<p>The magic SysRq (system request) allows you to access a low-level message system in the kernel. This will work as long as there hasn’t been a kernel panic, and can provide you with a way of rescuing the system. To access the key combination you need to hold <strong>Alt + SysRq + Command</strong> where command is the specific feature you want to access. The SysRq key is usually the same as the Print Screen key. A table of the available commands are found at the table at the bottom of this article, but the main one you will probably use is:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Alt + SysRq + REISUB              <span class="o">(</span>slowly <span class="nb">type </span>the R E I S U B<span class="o">)</span>
</code></pre></div></div> <p>This will kill all process except init, sync the mounted file systems, remount the file systems in read-only mode and reboot the system. There are a few ways to try and remember the order REISUB, the one I use is “Reboot Even If System Utterly Broken”, you could also just remember that it is ‘BUSIER’ backwards. Hope it comes in handy, here is the table of all the commands:</p> <table> <thead> <tr> <th>Command</th> <th>Description</th> </tr> </thead> <tbody> <tr> <td>0-9</td> <td>Set the console log level, i.e., change the type of kernel messages that are output</td> </tr> <tr> <td>b</td> <td>Immediately reboot the system, without unmounting or syncing filesystems</td> </tr> <tr> <td>c</td> <td>Perform a system crash. A crashdump will be taken if configured.</td> </tr> <tr> <td>d</td> <td>Display all currently held locks</td> </tr> <tr> <td>e</td> <td>Send the SIGTERM signal to all processes except init (PID 1)</td> </tr> <tr> <td>g</td> <td>Emergency support for switching back to the kernel’s framebuffer console</td> </tr> <tr> <td>h</td> <td>Output a terse help document to the console</td> </tr> <tr> <td>i</td> <td>Send the SIGKILL signal to all processes except init</td> </tr> <tr> <td>j</td> <td>Forcibly “Just thaw it” – filesystems frozen by the FIFREEZE ioctl</td> </tr> <tr> <td>k</td> <td>Kill all processes on the current virtual console</td> </tr> <tr> <td>l</td> <td>Shows a stack backtrace for all active CPUs</td> </tr> <tr> <td>m</td> <td>Output current memory information to the console</td> </tr> <tr> <td>n</td> <td>Reset the nice level of all high-priority and real-time tasks</td> </tr> <tr> <td>o</td> <td>Shut off the system</td> </tr> <tr> <td>p</td> <td>Output the current registers and flags to the console</td> </tr> <tr> <td>q</td> <td>Display all active high-resolution timers and clock sources</td> </tr> <tr> <td>r</td> <td>Switch the keyboard from raw mode</td> </tr> <tr> <td>s</td> <td>Sync all mounted filesystems</td> </tr> <tr> <td>t</td> <td>Output a list of current tasks and their information to the console</td> </tr> <tr> <td>u</td> <td>Remount all mounted filesystems in read-only mode</td> </tr> <tr> <td>v</td> <td>Forcefully restores framebuffer console</td> </tr> <tr> <td>w</td> <td>Display list of blocked tasks</td> </tr> <tr> <td>y</td> <td>Show global CPU registers (SPARC-64 specific)</td> </tr> <tr> <td>z</td> <td>Dump the ftrace buffer</td> </tr> <tr> <td>w</td> <td>Display list of blocked tasks</td> </tr> <tr> <td>y</td> <td>Show global CPU registers (SPARC-64 specific)</td> </tr> <tr> <td>z</td> <td>Dump the ftrace buffer</td> </tr> </tbody> </table>]]></content><author><name></name></author><category term="linux"/><summary type="html"><![CDATA[How to safely reboot a locked linux machine]]></summary></entry><entry><title type="html">Quick way to remove X Server for running a headless server</title><link href="https://seanelvidge.github.io/blog/2014/remove-X-server/" rel="alternate" type="text/html" title="Quick way to remove X Server for running a headless server"/><published>2014-05-10T07:35:00+00:00</published><updated>2014-05-10T07:35:00+00:00</updated><id>https://seanelvidge.github.io/blog/2014/remove-X-server</id><content type="html" xml:base="https://seanelvidge.github.io/blog/2014/remove-X-server/"><![CDATA[<p>I use my Raspberry Pi as a headless server so do not need anything that relies on X11, this is a quick way to get rid of everything that depends on X11 to save some space.</p> <p>Although you can get Raspberry Pi OSs which are very minimal (i.e. do not start with the X Server) I’ve found that <a href="https://www.raspberrypi.com/software/">Raspbian</a> is the most stable (Debian-based) OS for the Raspberry Pi, and so that is what I use. It is also really easy to set up to use as a headless server.</p> <p>Flash the OS to your SD card, boot your Raspberry Pi with it and as long as you have a wired internet connection to it, no need to use a screen. Simply SSH into the machine with the username ‘pi’ and password ‘raspberry’ (if you aren’t sure what the IP address of your Pi is you can either look on your router or I find using the Android App <a href="https://play.google.com/store/apps/details?id=com.overlook.android.fing">Fing</a> the easiest way).</p> <p>The first time you login you may want to run the Raspbian config programme:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>raspi-config
</code></pre></div></div> <p>Now the quick way to remove X11:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>apt-get remove <span class="nt">--auto-remove</span> <span class="nt">--purge</span> libx11-.<span class="k">*</span>
</code></pre></div></div> <p>The ‘–purge’ command in apt-get will remove everything which is associated with libx11, a nice quick way to save a load of space. If you so wish you can always check if a particular package is installed or not with:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>apt-cache policy package
</code></pre></div></div> <p>Where package is the package you want to check if it is installed or no. If it is installed the version number will be returned if not you will some text including the line ‘Installed: (none)’.</p>]]></content><author><name></name></author><category term="linux"/><summary type="html"><![CDATA[Remove X Server]]></summary></entry><entry><title type="html">Making Files and Folders Lowercase</title><link href="https://seanelvidge.github.io/blog/2013/making-lowercase/" rel="alternate" type="text/html" title="Making Files and Folders Lowercase"/><published>2013-10-21T12:32:00+00:00</published><updated>2013-10-21T12:32:00+00:00</updated><id>https://seanelvidge.github.io/blog/2013/making-lowercase</id><content type="html" xml:base="https://seanelvidge.github.io/blog/2013/making-lowercase/"><![CDATA[<p>Very occasionally I want to make all the files and folders of a particular directory lowercase (usually when porting an existing directory structure from Windows to Linux) this is how I do it.</p> <p>You could set up some form of recursive renaming script in a similar fashion to my post on <a href="https://seanelvidge.github.io/blog/2011/batch-process-in-bash/">Batch Process in Bash</a>. But it is much nicer to do it in just the one line, assume we want to change all the file and folder names inside the folder ‘/home/sean/windows/’:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>find /home/sean/windows/ <span class="nt">-depth</span> <span class="nt">-exec</span> rename <span class="s1">'s/(.*)\/([^\/]*)/$1\/\L$2/'</span> <span class="o">{}</span> <span class="se">\;</span>
</code></pre></div></div> <p>Job done!</p>]]></content><author><name></name></author><category term="linux"/><summary type="html"><![CDATA[How to make all files lowercase]]></summary></entry><entry><title type="html">Variance in TV Viewing Figures</title><link href="https://seanelvidge.github.io/blog/2013/variance-in-tv/" rel="alternate" type="text/html" title="Variance in TV Viewing Figures"/><published>2013-04-16T09:52:00+00:00</published><updated>2013-04-16T09:52:00+00:00</updated><id>https://seanelvidge.github.io/blog/2013/variance-in-tv</id><content type="html" xml:base="https://seanelvidge.github.io/blog/2013/variance-in-tv/"><![CDATA[<p>It is a fairly safe assumption that viewing figures for TV shows typically drop over time. But what I was thinking about this morning is how many people just turn on the TV and watch whatever is on, is that something we can work out from TV videwing figures?</p> <p>To start with lets consider “Grey’s Anatomy”. The viewing figure data is from <a href="http://abcmedianet.com/web/homepage/default.aspx" target="_blank">ABC Medianet</a> and initially we just plot the number of viewers per episode which results in the below graph.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/overall2-480.webp 480w,/assets/img/overall2-800.webp 800w,/assets/img/overall2-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/overall2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>The first thing to notice in the above plot, is the large spike of around 38 million viewers for episode 24. This is caused by being the lead out show after Super Bowl XL. The brown circles plotted represent the start of a new season, as very often a new season (with the associated advertising) leads to a bump in viewing figures.</p> <p>We can also see from the plot that over time the number of viewers for the show has steadily decreased. And the red and blue curves are polynomial fits to the data to try and track that change in viewers. The red curve ignores the viewing figure from after the Super Bowl, treating it as an outlier. To look at the variation in users we can subtract the overall trend of viewers from the data and just look at the “noise”.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/data-minus-trend-480.webp 480w,/assets/img/data-minus-trend-800.webp 800w,/assets/img/data-minus-trend-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/data-minus-trend.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>However, this “noise” also contains the trend of an increase in viewers at the start of a new season and this diminishing over the season. To try and remove this we look at the Hilbert-Huang transform of the data minus the trend, breaking the curve into 7 intrinsic mode functions (IMF):</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/IMFs-480.webp 480w,/assets/img/IMFs-800.webp 800w,/assets/img/IMFs-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/IMFs.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>What we discover in the 4th IMF is the following trend, made larger below so it is more visible, with the red vertical lines indicating where a new season begins.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/EMD-Season-Start-480.webp 480w,/assets/img/EMD-Season-Start-800.webp 800w,/assets/img/EMD-Season-Start-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/EMD-Season-Start.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>You can see that the peaks do not always match where a season begins (which was also reflected in the very first plot), but very often they do. This means that we can now plot the true “fluctuations” in viewer numbers by subtracting the above graph from our “noise” graph.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/viewer-noise-480.webp 480w,/assets/img/viewer-noise-800.webp 800w,/assets/img/viewer-noise-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/viewer-noise.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>It looks like, in this plot, that the noise in viewing figures is decreasing over time. However since we know that there is a decreasing number of viewers we calculate the normalised standard deviation for each season. This is done by finding the standard deviation of a season and dividing it by the range of viewers for that season. This is presented in the table below.</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code>| Season Number | Standard Deviation (Millions) | Range of Viewers (Million) | (Standard Deviation / Range ) <span class="se">\*</span> 100 (%) |
| :-----------: | :---------------------------: | :------------------------: | :--------------------------------------: |
|       1       |             1.19              |            5.97            |                  19.99                   |
|       2       |             1.71              |            9.72            |                  17.60                   |
|       3       |             1.82              |            8.88            |                  20.45                   |
|       4       |             1.39              |            6.82            |                  20.31                   |
|       5       |             1.43              |            5.36            |                  26.76                   |
|       6       |             1.34              |            7.16            |                  18.70                   |
|       7       |             1.09              |            5.19            |                  21.10                   |
|       8       |             0.66              |            3.93            |                  16.88                   |
|       9       |             0.59              |            3.56            |                  16.67                   |
</code></pre></div></div> <p>The percentage column has a mean value of 19.83% itself with a standard deviation of 3.06%. So we can conslude that the standard deviation of the noise in viewers is about 20% of the range of viewers. Is this a “standard value”? Or is it somehow tied to Grey’s Anatomy?</p> <p>Below I have generated the same plots as above for the shows ‘How I Met Your Mother’ and ‘Desperate Housewives’ which can be seen in the following galleries:</p> <p>How I Met Your Mother:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/himym-viewing-figures-480.webp 480w,/assets/img/himym-viewing-figures-800.webp 800w,/assets/img/himym-viewing-figures-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/himym-viewing-figures.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/himym-data-minus-trend-480.webp 480w,/assets/img/himym-data-minus-trend-800.webp 800w,/assets/img/himym-data-minus-trend-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/himym-data-minus-trend.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/himym-IMFS-480.webp 480w,/assets/img/himym-IMFS-800.webp 800w,/assets/img/himym-IMFS-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/himym-IMFS.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/himym-emd-composition-480.webp 480w,/assets/img/himym-emd-composition-800.webp 800w,/assets/img/himym-emd-composition-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/himym-emd-composition.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/himym-noise-480.webp 480w,/assets/img/himym-noise-800.webp 800w,/assets/img/himym-noise-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/himym-noise.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Desperate Housewives:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/dh-viewing-figures-480.webp 480w,/assets/img/dh-viewing-figures-800.webp 800w,/assets/img/dh-viewing-figures-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/dh-viewing-figures.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/dh-data-minus-trend-480.webp 480w,/assets/img/dh-data-minus-trend-800.webp 800w,/assets/img/dh-data-minus-trend-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/dh-data-minus-trend.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/dh-IMFs-480.webp 480w,/assets/img/dh-IMFs-800.webp 800w,/assets/img/dh-IMFs-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/dh-IMFs.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/dh-emd_composition-480.webp 480w,/assets/img/dh-emd_composition-800.webp 800w,/assets/img/dh-emd_composition-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/dh-emd_composition.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/dh-noise_in_viewers-480.webp 480w,/assets/img/dh-noise_in_viewers-800.webp 800w,/assets/img/dh-noise_in_viewers-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/dh-noise_in_viewers.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Desperate Housewives shows a similar pattern to Grey’s Anatomy in terms of the overall viewing figure trend. Increasing initially and then dropping off. ‘How I Met Your Mother’, however, shows a different pattern. Although there are less viewers, the numbers remain fairly constant throughout the show.</p> <p>From the above analysis we get a standard deviation (as a percentage of the range of viewers) as 17.17% (with a standard deviation of ~2.82%) for Desperate Housewives and 21.90% (standard deviation of 2.95%) for How I Met Your Mother.</p> <p>So the three values we’ve got are 19.83%, 17.17% and 21.90%. Giving an average of 19.63%, well three examples are enough for me! It certainly hints at the fact that the spread of noise in viewing figures is independent of the show, and may be a fact of TV viewing figures.</p>]]></content><author><name></name></author><category term="mathematics"/><summary type="html"><![CDATA[How many people just turn on How does Grey's Anatomy viewing figures vary over time?]]></summary></entry><entry><title type="html">Velocity Required for Loop-the-Loop</title><link href="https://seanelvidge.github.io/blog/2013/loop-the-loop/" rel="alternate" type="text/html" title="Velocity Required for Loop-the-Loop"/><published>2013-02-21T16:39:00+00:00</published><updated>2013-02-21T16:39:00+00:00</updated><id>https://seanelvidge.github.io/blog/2013/loop-the-loop</id><content type="html" xml:base="https://seanelvidge.github.io/blog/2013/loop-the-loop/"><![CDATA[<p>In this post we are going to work out (approximately) the minimum speed required to complete a loop-the-loop, we’ll do this via an energy argument. However, for ease, we are going to ignore friction! First we need to find the minimum speed required at the top of the loop.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/loop-the-loop-480.webp 480w,/assets/img/loop-the-loop-800.webp 800w,/assets/img/loop-the-loop-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/loop-the-loop.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>To get the minimum required speed to make the loop-the-loop, at the top of the loop we require the normal force (\(N\)) to be \(0\). Equating the forces at the top of the loop we have the weight of the car (\(mg\)) plus the normal force (\(N\)) equal to the centrifugal force (\(F\)), which is given by \(F=\frac{mv^2}{r}\) where \(r\) is the radius of the circle. Thus,</p> \[\begin{eqnarray*} \frac{mv_t^2}{r} &amp;=&amp; N+mg, \\ \frac{v_t^2}{r} &amp;=&amp; g,\\ v_t^2 &amp;=&amp; gr,\\ v_t &amp;=&amp; \sqrt{gr}. \end{eqnarray*}\] <p>Giving us a minimum velocity at the top of the loop, \(v_t\). We now proceed with the energy argument.</p> <p>The total energy at the top of the loop is equal to the potential energy at the top plus the kinetic energy at the top, respectively these are:</p> \[\begin{eqnarray*} PE_t &amp;=&amp; mgh = 2mgr,\\ KE_t &amp;=&amp; \frac{1}{2}mv_t^2 = \frac{1}{2}mgr. \end{eqnarray*}\] <p>Thus the total energy at the top is:</p> \[\begin{eqnarray*} E_t &amp;=&amp; 2mgr+\frac{1}{2}mgr,\\ &amp;=&amp; \frac{5}{2}mgr. \end{eqnarray*}\] <p>We now find the total energy at the bottom, since there is no potential energy, this is simply the kinetic energy,</p> \[E_b = \frac{1}{2}mv_b^2.\] <p>Where \(v_b\) is the speed we are looking for. With our assumptions, the energy at the top (\(E_t\)) equals the energy at the bottom (\(E_b\)) giving</p> \[\begin{eqnarray*} E_b &amp;=&amp; E_t,\\ \frac{1}{2}mv_b^2 &amp;=&amp; \frac{5}{2}mgr,\\ mv_b^2 &amp;=&amp; 5mgr,\\ v_b^2 &amp;=&amp; 5gr,\\ v_b &amp;=&amp; \sqrt{5gr}. \end{eqnarray*}\] <p>Thus we have found the speed required to complete a loop the loop of radius \(r\). For example, if the loop had a 4 metre diameter (2 metre radius) then the velocity required to complete the loop would be \(v = \sqrt{5\times g\times 2}=\sqrt{10g}\approx 9.9\).</p> <p>For convience we can approximate \(\sqrt{5gr}\) as:</p> \[\sqrt{5\times 9.81\times r}=\sqrt{49.05r}\approx 7\sqrt{r}.\]]]></content><author><name></name></author><category term="mathematics"/><summary type="html"><![CDATA[What is the velocity required to complete a loop-the-loop]]></summary></entry><entry><title type="html">It’s Snowing Outside</title><link href="https://seanelvidge.github.io/blog/2013/snowing-outside/" rel="alternate" type="text/html" title="It’s Snowing Outside"/><published>2013-01-19T16:35:00+00:00</published><updated>2013-01-19T16:35:00+00:00</updated><id>https://seanelvidge.github.io/blog/2013/snowing-outside</id><content type="html" xml:base="https://seanelvidge.github.io/blog/2013/snowing-outside/"><![CDATA[<p>I’m sitting in my office, at home, watching the snow falling outside and it got me thinking….</p> <p>As is well known, chemically, water is made from hydrogen and oxygen (H2O), specifically, each water molecule is made from two hydrogen atoms bonded with an oxygen atom. In this bonding there are two left over pairs of electrons, and the whole molecule creates a rough tetrahedron.</p> <p>“Luckily” (from the point of view of this post) when dealing with hexagonal ice (ice Ih) (i.e. natural ice /snow) we get a perfect tetrahedron (see here and here for more details of this), hence the six-fold symmetry in snowflakes.</p> <p>Now we know this, we can work out just how unique the snow outside is, or the ice in your cup (perhaps you’re reading this in a warmer climate!) is. How many possible ways are there to create a tetrahedral structure like hexagonal ice?</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/water_molecule-480.webp 480w,/assets/img/water_molecule-800.webp 800w,/assets/img/water_molecule-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/water_molecule.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>With a little bit of thinking, and twisting the above image in your head, hopefully you’ll agree with me that there are 6 ways of arranging the water molecule in the ‘ice tetrahedron’. However, not every one of these possibilities is possible. Read the Wikipedia page on hydrogen bonds and then you’ll see that in fact only \(\frac{3}{2}\)  possible orientations are allowed. That is, for a crystal of N molecules, there are \(\left(\frac{3}{2}\right)^N\) ways to arrange the molecules inside that crystal.</p> <p>So, let us consider a snowball, say of 3 cm radius. How many molecules are there in that much snow?</p> <p>There are a number of ways of arriving at the number of molecules, but I’m going to go for the way which came to me first (rather than perhaps the best / most elegant solution (not that I know what that is!)). I considered the snow as water (because I know the molar mass of water!), so for that we just need to know the density of snow. Not so easy, it depends on various factors; as you have no doubt experienced, new snow feels a lot less dense then snow that has been sitting around for a week. Typically the densities vary between 8% and 50% the density of water. Once the snow is on the ground it settles under its own weight to a density of around 30%. Since the snow that got me thinking about this is fairly new, we’ll go for a density of 20%. That means 30 cm of snow would make 6 cm of water.</p> <p>So our 3 cm radius snow ball has a volume of \(\approx 113\,cm^3\) which would be \(22.6\, cm^3\) of water. A cubic centimetre of water weights 1 grams so the water content of our snowball would weigh 22.6 g.</p> <p>The molar mass of water is \(18.01528\, g\cdot mol^{-1}\) so there is</p> \[22.6 \times\frac{1}{18.01528}\approx 1.25 \mbox{ moles}.\] <p>Multiplying this number by Avogadro’s number (\(6.02\times 10^{23}\)) yields the number of molecules in the snowball:</p> \[1.25 \times 6.02\times 10^{23} \approx 7.5\times 10^{23}.\] <p>That means the possible number of orientations of the water molecules is</p> \[\left(\frac{3}{2}\right)^{7.5\times 10^{23}} \approx 10^{10^{23}}.\] <p>So how big is that number? Well it is stupidly big. We estimate that there is something like \(10^{80}\) atoms in the universe which isn’t even close to that number. So it is safe to say that every snowball that has ever been made, or ever will be made by people all over the Earth for the rest of the history of this planet, will always have a unique arrangements of water molecules!</p>]]></content><author><name></name></author><category term="mathematics"/><summary type="html"><![CDATA[Investigating the number of unique snowballs]]></summary></entry><entry><title type="html">The Crawshaw Method (for Quadratics)</title><link href="https://seanelvidge.github.io/blog/2012/the-Crawshaw-method/" rel="alternate" type="text/html" title="The Crawshaw Method (for Quadratics)"/><published>2012-05-01T20:49:00+00:00</published><updated>2012-05-01T20:49:00+00:00</updated><id>https://seanelvidge.github.io/blog/2012/the-Crawshaw-method</id><content type="html" xml:base="https://seanelvidge.github.io/blog/2012/the-Crawshaw-method/"><![CDATA[<p>Something all High School students (and above) need to know is how to factorize quadratic equations. However I am amazed how few people know a decent (and easy) way of doing this!</p> <p>I’ll keep this as simple as possible, and just show you how to use the method.</p> <p>First we consider a simple case (and sadly this is where a lot of the problems arise from!), we want to factorize the quadratic equation,</p> \[x^2+5x+6.\] <p>Now, as far as I know, it is universally taught that to factorize this you have to “find” two numbers that times together to make \(+6\) (the constant term) and add to make \(+5\) (the linear term). This is pretty easy, we choose the numbers \(+2\) and \(+3\), and then we simply write down the answer,</p> \[x^2+5x+6=(x+2)(x+3).\] <p>Easy.</p> <p>The problem is when you arrive at a question like,</p> \[3x^2-7x-6.\] <p>If we proceed in the same way as we were `taught’ above we need to find two numbers which times together to make \(-6\) and add to make \(-7\). We then need to try and work out what on Earth to do with these numbers, the problem is, it is not in any way obvious and quite a lot of guess work, or at least trial and error, is required.  The answer we would be looking for was</p> \[3x^2-7x-6=(3x+2)(x-3).\] <p>I think what is clear is that we need a concise, dare I say easy, method to solve any quadratic equation.</p> <p>Let me introduce the <em>Crawshaw method</em>.</p> <p>We first will apply the method to the ‘easy’ quadratic formula (the method is identical for all quadratics), you only need to remember that \(x=1x\), only we don’t write the \(1\). So the quadratic to solve is \(x^2+5x+6\).</p> <p>The first step of the method tells us that we need to find two numbers which add together to make \(+5\) and times to make \(1\times 6=6\), that is, the coefficient of the quadratic term (\(1\)) multiplied by the constant term (\(6\)). These numbers are \(2\) and \(3\).</p> <p>The second step is to rewrite the linear term as a combination of the numbers we have just found. So for this question the linear term is \(+5x\) the numbers we found were \(2\) and \(3\) so we will replace \(+5x\) in the quadratic with \(+2x+3x\). So our quadratic is now:</p> \[x^2+2x+3x+6.\] <p>Which is of course the exact same equation but now we can continue with the method.</p> <p>We now draw an imaginary line down the middle of the equation:</p> \[x^2+2x\quad/\quad+3x+6.\] <p>Next we factorize the left hand side, getting:</p> \[x(x+2)\quad/\quad+3x+6.\] <p>We then need to factorize the right hand side, but making sure that the bracket terms are the same, i.e.</p> \[x(x+2)\quad/\quad+3(x+2).\] <p>Then finally we get our two brackets (for the factorized answer) as the one bracket we already have, and the two terms that are on the outside of the brackets (i.e. in this case \(x\) and \(+3\)). Thus our answer becomes</p> \[(x+2)(x+3).\] <p>This method does seem more difficult for this ‘easy’ equation (i.e. one where the coefficient of the quadratic term is \(1\)) but the beauty of the Crawshaw method is that it works exactly the same for all quadratic equations.</p> <p>Now let us consider the second equation, that is \(3x^2-7x-6\). We approach it in exactly the same way.</p> <p>First find two numbers which times together to make \(3\times -6 = -18\) (that is the coefficient of the quadratic term multiplied by the constant term) and add together to make \(-7\). Such numbers are \(-9\) and \(+2\). So we now rewrite the linear term with these numbers (i.e. replacing \(-7x=-9x+2x\)) so we get:</p> \[3x^2-9x+2x-6.\] <p>Now we draw an imaginary line down the middle and factorize both sides of the equation:</p> \[\begin{eqnarray*} 3x^2-9x \quad &amp;/&amp; \quad 2x-6,\\ 3x(x-3) \quad &amp;/&amp; \quad +2(x-3). \end{eqnarray*}\] <p>So we then have our factorized solution,</p> \[3x^2-7x-6=(3x+2)(x-3).\] <p>See, wasn’t that easier?</p> <p>I present to you, the Crawshaw method.</p>]]></content><author><name></name></author><category term="mathematics"/><summary type="html"><![CDATA[How to solve quadratic equations using the Crawshaw method]]></summary></entry></feed>